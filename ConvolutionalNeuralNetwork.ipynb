{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivyson/Neural-Network-XOR/blob/main/ConvolutionalNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b024e3b8",
      "metadata": {
        "id": "b024e3b8"
      },
      "source": [
        "# Multi-Layered Perceptrons\n",
        "This architecture discussed from the previous sessions, Having input layer accepting one dimensioned array has actually paved a route for the CNN that we will be covering here in this session. MLPs are very simplistic, accepting data presented in a table format and learning from them, making decisions based on such data. Now, the real life data is much dimensioned than just a 1 dimensioned data, flattening this data straight away destroys the important data carried by this real life data. an image could be used as an example to illustrate this.\n",
        "\n",
        "One of the models we built before was using the MNIST-Number dataset which we used to predict a sketched number on an image. This model gave around 87% accuracy and it was behaving remarkably outstanding, but now, why would we want to develop a new architecture if the basic MLP can understand pictures too?. Now, the catch lies here, The MNIST dataset that was used was only kept at $ 28 \\times 28$ Pixel count, this meant we had to flatten the image to create 784 input nuerons, even though this is not a huge number to compute, as images become more advanced, we start getting the scales of $1020 \\times 720$ which will mean that we have to create an MLP with Input Nuerons of $\\approx 74$ Thousand. Pictures are now 4K too, which even increases the computational power required to deal with these pictures as you use the MLP. This is even much less of a concern ever since computational power can be bought, but accuracy is a major concern now.\n",
        "\n",
        "The MNIST dataset is made of only black and white colors, The white coloured pixels representing the drawing of a number, which is referred to a grey-scaling. Now pictures are not just black and white but consisting of complex colors which are Red, Green & Blue, This means that each pixel has an array of 3 values, Red, Green and Blue respectively. If the intention is to use an mlp on such images, the model prediction will be dramatically questionable, this is due the idea that the nearby pixels are carrying important information about each other, so directly flattening these pixels will cause the nearby pictures to be far from each other, hence the pattern will be lost, leading to incorrect predictions.\n",
        "\n",
        "This is not only observed on images but signals. The end goal for this project is to design a model that can understand the pattern in the EEG signals, But often than not, the signals also follow a specific pattern, Signals are continious and have huge value set at each point. So, for example, if you had a signal that looked like a wave like a heartbeat or sound wave, instead of treating it as something that moves over time, the MLP just sees a row of numbers without any idea of the order or shape of the signal. That’s already a problem, because signals are meaningful because of how they change over time. If you take away the structure of the signal, the model loses the chance to understand patterns like rising and falling edges, repetition, or trends that appear in sequence.  Another big issue is that MLPs connect every input to every neuron in the next layer. So if you give it a signal that has, say, 10,000 numbers, which is not unusual for audio and other high-resolution signals, and your first hidden layer has just 100 neurons, you now have 1 million weights. That’s a lot of numbers for the network to learn, and it means the model can easily memorize the training data instead of learning general patterns. It also means training becomes slower and more demanding on the computer. All this effort — and yet, the model still isn’t really understanding what’s happening across time in the signal.\n",
        "\n",
        "Now This pushes us to finding more robust methods of dealing with such datasets and find more efficient and reliable ways in which we can compute a model that can predict such datasets. Which is what we will be covering here, **CNNs**\n",
        "\n",
        "# Convulational Nueral Networks (CNNs)\n",
        "The name of the Model comes from the operation that happens under the hood of this architecture. Instead of Connecting every input to the next nueron as seen in the MLP, CNNs make use of Convolutiona Filters to look for local regions of the dataset. These filters are moved along the dataset, detecting the patterns within the input data, such as the edges(spikes), textures(for images) & specific shapes. The `Filters` are also known as `Kernel` Windows, becuase they are relatively smaller matrix system than the input data, which is imposed on the input data and then perfoming some mathematical operation within that specific dataset. The mathemathical operation is *Element-wise multiplication* then Adding the product of the output data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U0q5-IEKkzD0",
      "metadata": {
        "id": "U0q5-IEKkzD0"
      },
      "source": [
        "\n",
        "<img src=\"https://github.com/Ivyson/Neural-Network-XOR/blob/main/Assets/Media/Convolution.gif?raw=1\" alt=\"Convolution Operation Demonstration\" width=\"800\"/>\n",
        "\n",
        "\n",
        "Oftenly this part is done a couple of times by a couple of filters, each filter extracting specific information about the signal. This is then followed by the **Activation Function**. This function performs a specific manipulation to the input data, Example of it includes:  *Rectified Linear Unit* which replaces all the non positive values by 0 and then leaving the positive values as is. This part here is important for allowing the nueral network to learn faster, Remember that when we have only values from 0 going up, the dataset is much more easier to interpret rather than when it lies both ways of the cartesian plane. Even though this function is not always useful, we can also use *Tanh(x)* function which squashes every data to the range of [-1, 1], Another useful function could be a Leaky Relu or Parameterised relu, which squashes the negative values to be closer to zero and then keeping the positive values as they are.. Which Activation Function is better entirely depends on the application of your model. Also, to keep in mind, the data that is squashed or manipulated is **not** the input data but the convolved data, For an example, If we apply a Relu on the dataset that was convolved using a filter that extracts sharp edges from a picture, the relu will replace the dataset that was detected to have less(or negative) sharp edges with zeros, Allowing us to sharply detect edges on the image. This process is then followed by `Pooling`\n",
        "\n",
        "`Pooling`, which down samples or super - samples the data from the Actication Function, for the purpose of this paper, we will be focusing on Down sampling because we need to feed the Network less data at the end of the day while retrieving enough information about the input data as much as possible.\n",
        "\n",
        "**Pooling** is a matrix system that hovers around the output matrix of the Convolution and the input data, the Pooling process extracts key feautures in that output by retaining the important spatial information while shirinking the data. The Pooling process that will be used here will be *Max Pooling* Which will be a $2\\times 2$ Matrix that will hover around all the data from the convolution, finding the maximum in that small window of $2\\times 2$ and then ignoring all the other data. The Process of pooling is demonstrated below as follows\n",
        "\n",
        "<img src=\"https://github.com/Ivyson/Neural-Network-XOR/blob/main/Assets/Media/MaxPooling.gif?raw=1\" alt=\"Convolution Operation Demonstration\" width=\"900\"/>\n",
        "\n",
        "From the pooling demonstration above, we can see that even though the data i shrank into a smaller scale, the spatial information of the image is still retained but just represented as a smaller scale. Now, Finally after performing Convolution, Activation & Pooling a couple of times, we now have a smaller matrix which has just important dataset that we need, these are then flattened and then sent into an MLP architecture. MLP will be responsible for classification problems like identifying if the dataset represents a dog or a cat etc.. or any other manipulation from the data (Binary Classification, Regression etc..)\n",
        "\n",
        "# How do we select the right Filter\n",
        "Remember that the filter exctracts important features from the input data, More Features needed implies more Filters required. Because we need to extract more features from the input dataset , we should use something around 8 or 16 filters if we are dealing with smaller dataset, and 32 or 64 for larger datasets. and then as you move away from the Input data, we can then use lesser filters, However the number of filters used is experimental to each problem. How many Filters you need depends on the complexity and the sensitivity of your problem statement, but generally, 3 filters would be able to extract a few feautures in your dataset, but 10 would be exponentially better but computationally would take longer to train.\n",
        "\n",
        "The data within the filters is initially randomly generated, Therefore, they are not really extracting anything tangible from the input data, but the accuracy depends on the feed forward and the back propagation of the network.\n",
        "## How the process occurs\n",
        "During each iteration, the network takes the input data like a signal or image and applies these random filters to extract features. The filter performs a convolution operation over the input, creating a feature map. The feature map is then passed through activation functions like ReLU, and eventually through pooling layers. After the forward pass, the network makes a prediction (e.g., classifying the signal or image). The model then compares this prediction to the true label (ground truth) using a loss function (e.g., Mean Squared Error or Cross-Entropy Loss).\n",
        "\n",
        "After calculating the loss, the network uses backpropagation to update the filters. The network calculates how much each filter contributed to the error Then, it adjusts the filter values using a technique called gradient descent(Described On the first MLP Notes) to minimize the error. This means the filters change to better capture important patterns in the data. The learning rate taht was parsed in initially controls how much the filter values change during each update.\n",
        "- Initially during the early training, The filters will still look random, and the feature maps produced might not make much sense. However, as the model learns from the data, it starts adjusting the filters to highlight useful feautures like edge, textures etc.. (These have been mentioned a couple of times now...) Now as the Training continues, the filters specialise in different aspects. The fact that these are randomly generated is what gives us hope that these filters **Will** focus on different aspects of the signal to give us a correct output. If the filters were all the same then we would be having the same filters focusing on the same feature, outputting the same output, causing the model to not learn anything useful at all.\n",
        "\n",
        "\n",
        "\n",
        "# Media used\n",
        "If the media is having problems being played on your end, Click the below links:\n",
        "\n",
        "[Convolution Filters Demonstration](/Assets/Media/Convolution.mov)\n",
        "\n",
        "[Max Pooling Demonstration](/Assets/Media/MaxPooling.mov)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# References\n",
        "[Brain Tumor Detection Dataset](https://www.kaggle.com/code/abutahimhabiby/brain-tumor-detection-cnn-clahe-92-16-val)\n",
        "\n",
        "[Convolutional Filters Animation](https://deeplizard.com/resource/pavq7noze2)\n",
        "\n",
        "[Convolution Max Pooling Example](https://deeplizard.com/resource/pavq7noze3)\n",
        "\n",
        "[MIT Lecture](https://youtu.be/oGpzWAlP5p0?si=GWiR08AY9alW7Ie7)\n",
        "\n",
        "[3B1B ](https://youtu.be/KuXjwB4LzSA?si=BDwR451OXyqXuSVm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "MXKCI5NeYhgA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MXKCI5NeYhgA",
        "outputId": "4a1b6ac9-e589-4c7d-daae-b8ee0234147f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "--- Loading Model ---\n",
            "ERROR: Model file not found at 'brain_tumor_cnn.pkl'\n",
            "CuPy found! Using GPU acceleration for NumPy operations\n",
            "GPU acceleration: Enabled\n",
            "Loading data from /content/drive/MyDrive/Colab Notebooks/eeg_data/Epileptic Seizure Recognition.csv...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CUDARuntimeError",
          "evalue": "cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCUDARuntimeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-54166600d541>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-54166600d541>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m     \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_epilepsy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# Transfer to GPU if using CuPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-54166600d541>\u001b[0m in \u001b[0;36mload_epilepsy_data\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \u001b[0;31m# Convert data to proper format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m179\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to float64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1706\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Labels (1-5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupy/_creation/from_data.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(obj, dtype, copy, order, subok, ndmin, blocking)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core._array_default\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__new__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core._ndarray_base._init\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.alloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/device.pyx\u001b[0m in \u001b[0;36mcupy.cuda.device.get_device_id\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy_backends/cuda/api/runtime.pyx\u001b[0m in \u001b[0;36mcupy_backends.cuda.api.runtime.getDevice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy_backends/cuda/api/runtime.pyx\u001b[0m in \u001b[0;36mcupy_backends.cuda.api.runtime.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCUDARuntimeError\u001b[0m: cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.signal # Used for 2 dimensional Convolution\n",
        "import pickle\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, Optional, List, Dict, Any, Callable, Union # Keep type hints, : String/Float etc....\n",
        "from sklearn.model_selection import train_test_split # For splitting data into training dt and Testing dt...\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import scipy\n",
        "drive.mount('/content/drive')\n",
        "!pip install opencv-python\n",
        "\n",
        "\n",
        "# These are for Adam Optimiser tools.\n",
        "ADAM_BETA1 = 0.9\n",
        "ADAM_BETA2 = 0.999\n",
        "ADAM_EPSILON = 1e-8\n",
        "LEAKY_RELU_ALPHA = 0.01\n",
        "\n",
        "# Activation FUNCTIONS\n",
        "def _sigmoid(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Returns a much stable Sigmoid function.\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def _sigmoid_derivative(output: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Derivative of sigmoid (using its output).\"\"\"\n",
        "    return output * (1 - output)\n",
        "\n",
        "def _relu(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Rectified Linear Unit activation.\"\"\"\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def _relu_derivative(output: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Derivative of ReLU.\"\"\"\n",
        "    return np.where(output > 0, 1, 0) # This here is because the derivative at 0 is undefined\n",
        "\n",
        "def _leaky_relu(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Leaky Rectified Linear Unit activation.\"\"\"\n",
        "    return np.where(x > 0, x, x * LEAKY_RELU_ALPHA)\n",
        "\n",
        "def _leaky_relu_derivative(output: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Derivative of Leaky ReLU.\"\"\"\n",
        "    return np.where(output > 0, 1, LEAKY_RELU_ALPHA)\n",
        "\n",
        "def _softmax(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Softmax activation function.\"\"\"\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / (np.sum(exp_x, axis=-1, keepdims=True) + 1e-9) # Add epsilon for stability\n",
        "\n",
        "def _softmax_derivative_cross_entropy(output: np.ndarray, y_true: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the gradient of the cross-entropy loss with respect to the\n",
        "    inputs of the softmax function (often denoted dL/dz).\n",
        "    This combined gradient is simply (output - y_true).\n",
        "    Note: This function isn't the derivative of softmax itself, but\n",
        "          the combined gradient needed for backprop when using softmax + cross-entropy.\n",
        "    The `output_gradient` passed to the Activation layer's backward pass in this case\n",
        "    should be y_true. The loss gradient calculation should return y_pred - y_true.\n",
        "    So, the backward pass of Softmax Activation simplifies.\n",
        "    \"\"\"\n",
        "    pass # Logic Implemented on the CNN Already\n",
        "\n",
        "def _linear(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Linear activation (identity).\"\"\"\n",
        "    return x\n",
        "\n",
        "def _linear_derivative(output: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Derivative of linear activation.\"\"\"\n",
        "    return np.ones_like(output)\n",
        "\n",
        "ACTIVATION_FUNCTIONS: Dict[str, Callable[[np.ndarray], np.ndarray]] = {\n",
        "    'sigmoid': _sigmoid,\n",
        "    'relu': _relu,\n",
        "    'leaky_relu': _leaky_relu,\n",
        "    'softmax': _softmax,\n",
        "    'linear': _linear,\n",
        "}\n",
        "\n",
        "ACTIVATION_DERIVATIVES: Dict[str, Callable[[np.ndarray], np.ndarray]] = {\n",
        "    'sigmoid': _sigmoid_derivative,\n",
        "    'relu': _relu_derivative,\n",
        "    'leaky_relu': _leaky_relu_derivative,\n",
        "    'softmax': lambda output: output * (1-output),\n",
        "    'linear': _linear_derivative,\n",
        "}\n",
        "\n",
        "\n",
        "# tEH Loss Functions\n",
        "\n",
        "def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    \"\"\"Calculates Mean Squared Error loss.\"\"\"\n",
        "    return np.mean(np.sum((y_true - y_pred) ** 2, axis=1))\n",
        "\n",
        "def mean_squared_error_gradient(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Calculates the gradient of Mean Squared Error loss.\"\"\"\n",
        "    return 2 * (y_pred - y_true) / y_true.shape[0]\n",
        "\n",
        "def categorical_cross_entropy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    \"\"\"Calculates Categorical Cross-Entropy loss.\"\"\"\n",
        "    # Clip predictions to avoid log(0)\n",
        "    epsillon = 1e-9\n",
        "    y_pred_clipped = np.clip(y_pred, epsillon, 1 - epsillon)\n",
        "    return -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
        "\n",
        "def categorical_cross_entropy_gradient(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculates the gradient of CCE loss w.r.t y_pred.\n",
        "    When combined with Softmax, the gradient w.r.t the Softmax *input* simplifies.\n",
        "    \"\"\"\n",
        "    return (y_pred - y_true) / y_true.shape[0]\n",
        "\n",
        "\n",
        "LOSS_FUNCTIONS: Dict[str, Callable] = {\n",
        "    'mse': mean_squared_error,\n",
        "    'categorical_crossentropy': categorical_cross_entropy,\n",
        "}\n",
        "\n",
        "LOSS_GRADIENTS: Dict[str, Callable] = {\n",
        "    'mse': mean_squared_error_gradient,\n",
        "    'categorical_crossentropy': categorical_cross_entropy_gradient,\n",
        "}\n",
        "\n",
        "#Base Layer Architecture Class..\n",
        "class Layer:\n",
        "    \"\"\"Base class for all network layers.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.input: Optional[np.ndarray] = None\n",
        "        self.output: Optional[np.ndarray] = None\n",
        "        self._has_weights = False # Flag to indicate if layer has trainable weights\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Perform the forward pass.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: float, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass.\n",
        "        kwargs might include Adam parameters like t, beta1, beta2, epsilon.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def has_weights(self) -> bool:\n",
        "        \"\"\"Check if the layer has trainable weights.\"\"\"\n",
        "        return self._has_weights\n",
        "\n",
        "\n",
        "class Activation(Layer):\n",
        "    \"\"\"Applies an activation function element-wise.\"\"\"\n",
        "    def __init__(self, activation_name: str):\n",
        "        \"\"\"\n",
        "        Initialize activation layer.\n",
        "\n",
        "        :param activation_name: Name of the activation function\n",
        "                                ('sigmoid', 'relu', 'leaky_relu', 'softmax', 'linear').\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if activation_name not in ACTIVATION_FUNCTIONS:\n",
        "            raise ValueError(f\"Unknown activation function: '{activation_name}'\")\n",
        "        self.activation_name = activation_name\n",
        "        self.activation_func = ACTIVATION_FUNCTIONS[activation_name]\n",
        "        self.activation_derivative = ACTIVATION_DERIVATIVES.get(activation_name)\n",
        "        if self.activation_derivative is None and self.activation_name != 'softmax':\n",
        "             raise ValueError(f\"Derivative for '{activation_name}' not found.\")\n",
        "\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Perform the forward pass applying the activation function.\"\"\"\n",
        "        self.input = input_data\n",
        "        self.output = self.activation_func(input_data)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: Optional[float] = None, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass through the activation function.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer.\n",
        "        :param learning_rate: Not used for activation layer.\n",
        "        :param kwargs: May include y_true for Softmax+CCE simplification.\n",
        "        :return: Gradient with respect to the input of this layer.\n",
        "        \"\"\"\n",
        "        if self.activation_name == 'softmax':\n",
        "            return output_gradient\n",
        "        elif self.activation_derivative:\n",
        "             # Apply chain rule: dL/dx = dL/dy * dy/dx\n",
        "             # where y = activation_func(x)\n",
        "             # dy/dx is the activation_derivative evaluated at the output y (or input x sometimes)\n",
        "            return output_gradient * self.activation_derivative(self.output)\n",
        "        else:\n",
        "            raise RuntimeError(f\"Cannot perform backward pass for {self.activation_name} without derivative.\")\n",
        "\n",
        "class Conv2D(Layer):\n",
        "    \"\"\"2D Convolutional Layer.\"\"\"\n",
        "    def __init__(self, input_shape: Tuple[int, int, int], kernel_size: Tuple[int, int], depth: int):\n",
        "        \"\"\"\n",
        "        Initialize convolutional layer.\n",
        "\n",
        "        :param input_shape: Shape of the input volume (height, width, channels).\n",
        "        :param kernel_size: Size of the convolution kernel (height, width).\n",
        "        :param depth: Number of kernels/filters (output depth).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._has_weights = True\n",
        "        self.input_height, self.input_width, self.input_channels = input_shape\n",
        "        self.kernel_height, self.kernel_width = kernel_size\n",
        "        self.depth = depth # Number of output filters\n",
        "\n",
        "        if not (isinstance(kernel_size, tuple) and len(kernel_size) == 2):\n",
        "             raise ValueError(\"kernel_size must be a tuple of two integers (height, width).\")\n",
        "        if not (isinstance(input_shape, tuple) and len(input_shape) == 3):\n",
        "             raise ValueError(\"input_shape must be a tuple of three integers (height, width, channels).\")\n",
        "\n",
        "        # Xavier initialization\n",
        "        self.kernels_shape = (self.kernel_height, self.kernel_width, self.input_channels, self.depth)\n",
        "        limit = np.sqrt(6 / (np.prod(kernel_size) * self.input_channels + np.prod(kernel_size) * self.depth))\n",
        "        self.kernels = np.random.uniform(-limit, limit, self.kernels_shape)\n",
        "        self.biases = np.zeros(self.depth) # One bias per output filter\n",
        "\n",
        "        # Adam optimizerz\n",
        "        self.m_kernels = np.zeros_like(self.kernels)\n",
        "        self.v_kernels = np.zeros_like(self.kernels)\n",
        "        self.m_biases = np.zeros_like(self.biases)\n",
        "        self.v_biases = np.zeros_like(self.biases)\n",
        "\n",
        "        self.output_height = self.input_height - self.kernel_height + 1\n",
        "        self.output_width = self.input_width - self.kernel_width + 1\n",
        "        if self.output_height <= 0 or self.output_width <= 0:\n",
        "            raise ValueError(f\"Kernel size {kernel_size} is too large for input shape {input_shape[:2]}.\")\n",
        "        self.output_shape = (self.output_height, self.output_width, self.depth)\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the forward pass using convolution.\n",
        "\n",
        "        Note: This implementation uses scipy.signal.convolve2d which is\n",
        "              computationally expensive for large inputs/kernels compared to\n",
        "              optimized libraries (like TensorFlow, PyTorch) using im2col or FFT.\n",
        "\n",
        "        :param input_data: Input data of shape (batch_size, height, width, channels).\n",
        "        :return: Output feature map of shape (batch_size, new_height, new_width, depth).\n",
        "        \"\"\"\n",
        "        self.input = input_data\n",
        "        batch_size = input_data.shape[0]\n",
        "\n",
        "        # Initialize output array\n",
        "        self.output = np.zeros((batch_size, *self.output_shape))\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for d in range(self.depth):\n",
        "                output_feature_map = np.zeros((self.output_height, self.output_width))\n",
        "                for c in range(self.input_channels):\n",
        "                    # Kernel shape: (kH, kW, InChannels, OutDepth)\n",
        "                    kernel_slice = self.kernels[:, :, c, d]\n",
        "                    input_slice = self.input[i, :, :, c]\n",
        "                    output_feature_map += scipy.signal.convolve2d(\n",
        "                        input_slice, kernel_slice, mode='valid'\n",
        "                    )\n",
        "                # Add bias\n",
        "                self.output[i, :, :, d] = output_feature_map + self.biases[d]\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def _adam_update(self, param: np.ndarray, grad: np.ndarray, m: np.ndarray, v: np.ndarray,\n",
        "                     learning_rate: float, t: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"Helper function to perform Adam update.\"\"\"\n",
        "        m = ADAM_BETA1 * m + (1 - ADAM_BETA1) * grad\n",
        "        v = ADAM_BETA2 * v + (1 - ADAM_BETA2) * (grad ** 2)\n",
        "\n",
        "        m_hat = m / (1 - ADAM_BETA1 ** t)\n",
        "        v_hat = v / (1 - ADAM_BETA2 ** t)\n",
        "\n",
        "        # Update\n",
        "        param -= learning_rate * m_hat / (np.sqrt(v_hat) + ADAM_EPSILON)\n",
        "        return param, m, v\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: float, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass to compute gradients and update weights using Adam.\n",
        "\n",
        "        Note: This implementation uses scipy.signal correlate2d/convolve2d,\n",
        "              which can be slow.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer, shape (batch_size, out_h, out_w, depth).\n",
        "        :param learning_rate: Learning rate for the optimizer.\n",
        "        :param kwargs: Expected to contain 't' (Adam timestep).\n",
        "        :return: Gradient with respect to the input of this layer.\n",
        "        \"\"\"\n",
        "        if 't' not in kwargs:\n",
        "            raise ValueError(\"Adam timestep 't' is required for backward pass.\")\n",
        "        t = kwargs['t']\n",
        "\n",
        "        batch_size = output_gradient.shape[0]\n",
        "        kernels_gradient = np.zeros_like(self.kernels)\n",
        "        biases_gradient = np.zeros_like(self.biases)\n",
        "        input_gradient = np.zeros_like(self.input)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for d in range(self.depth):\n",
        "                biases_gradient[d] += np.sum(output_gradient[i, :, :, d])\n",
        "\n",
        "                for c in range(self.input_channels):\n",
        "                    input_slice = self.input[i, :, :, c]\n",
        "                    output_grad_slice = output_gradient[i, :, :, d]\n",
        "                    kernels_gradient[:, :, c, d] += scipy.signal.correlate2d(\n",
        "                        input_slice, output_grad_slice, mode='valid'\n",
        "                    )\n",
        "\n",
        "                    kernel_slice = self.kernels[:, :, c, d]\n",
        "                    rotated_kernel = np.rot90(kernel_slice, 2) # Rotate 180 degrees\n",
        "                    input_gradient[i, :, :, c] += scipy.signal.convolve2d(\n",
        "                        output_grad_slice, rotated_kernel, mode='full'\n",
        "                    )\n",
        "\n",
        "        # Update kernels and biases using Adam\n",
        "        self.kernels, self.m_kernels, self.v_kernels = self._adam_update(\n",
        "            self.kernels, kernels_gradient, self.m_kernels, self.v_kernels, learning_rate, t\n",
        "        )\n",
        "        self.biases, self.m_biases, self.v_biases = self._adam_update(\n",
        "            self.biases, biases_gradient, self.m_biases, self.v_biases, learning_rate, t\n",
        "        )\n",
        "\n",
        "        return input_gradient\n",
        "\n",
        "\n",
        "class Conv1D(Layer): # Extends From Layer class..\n",
        "    \"\"\"1D Convolutional Layer for signal data like EEG.\"\"\"\n",
        "    def __init__(self, input_shape: Tuple[int, int], kernel_size: int, depth: int):\n",
        "        \"\"\"\n",
        "        Initialize 1D convolutional layer.\n",
        "\n",
        "        :param input_shape: Shape of the input signal (length, channels).\n",
        "        :param kernel_size: Size of the convolution kernel (length).\n",
        "        :param depth: Number of kernels/filters (output depth).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._has_weights = True\n",
        "        self.input_length, self.input_channels = input_shape\n",
        "        self.kernel_length = kernel_size\n",
        "        self.depth = depth  # Number of output filters\n",
        "\n",
        "        if not isinstance(kernel_size, int):\n",
        "            raise ValueError(\"kernel_size must be an integer for Conv1D.\")\n",
        "        if not (isinstance(input_shape, tuple) and len(input_shape) == 2):\n",
        "            raise ValueError(\"input_shape must be a tuple of two integers (length, channels).\")\n",
        "\n",
        "        # Xavier initialization\n",
        "        self.kernels_shape = (self.kernel_length, self.input_channels, self.depth)\n",
        "        limit = np.sqrt(6 / (self.kernel_length * self.input_channels + self.kernel_length * self.depth))\n",
        "        self.kernels = np.random.uniform(-limit, limit, self.kernels_shape)\n",
        "        self.biases = np.zeros(self.depth)  # One bias per output filter\n",
        "\n",
        "        # Adam optimizer\n",
        "        self.m_kernels = np.zeros_like(self.kernels)\n",
        "        self.v_kernels = np.zeros_like(self.kernels)\n",
        "        self.m_biases = np.zeros_like(self.biases)\n",
        "        self.v_biases = np.zeros_like(self.biases)\n",
        "\n",
        "        self.output_length = self.input_length - self.kernel_length + 1\n",
        "        if self.output_length <= 0:\n",
        "            raise ValueError(f\"Kernel size {kernel_size} is too large for input length {input_shape[0]}.\")\n",
        "        self.output_shape = (self.output_length, self.depth)\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the forward pass using 1D convolution.\n",
        "\n",
        "        :param input_data: Input data of shape (batch_size, length, channels).\n",
        "        :return: Output feature map of shape (batch_size, new_length, depth).\n",
        "        \"\"\"\n",
        "        self.input = input_data\n",
        "        batch_size = input_data.shape[0]\n",
        "\n",
        "        # Initialize output array\n",
        "        self.output = np.zeros((batch_size, *self.output_shape))\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for d in range(self.depth):\n",
        "                output_feature_map = np.zeros(self.output_length)\n",
        "                for c in range(self.input_channels):\n",
        "                    # Kernel shape: (kL, InChannels, OutDepth)\n",
        "                    kernel_slice = self.kernels[:, c, d]\n",
        "                    input_slice = self.input[i, :, c]\n",
        "\n",
        "                    # Use scipy's 1D convolution\n",
        "                    output_feature_map += scipy.signal.convolve(\n",
        "                        input_slice, kernel_slice, mode='valid'\n",
        "                    )\n",
        "\n",
        "                # Add bias\n",
        "                self.output[i, :, d] = output_feature_map + self.biases[d]\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def _adam_update(self, param: np.ndarray, grad: np.ndarray, m: np.ndarray, v: np.ndarray,\n",
        "                    learning_rate: float, t: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"Helper function to perform Adam update.\"\"\"\n",
        "        m = ADAM_BETA1 * m + (1 - ADAM_BETA1) * grad\n",
        "        v = ADAM_BETA2 * v + (1 - ADAM_BETA2) * (grad ** 2)\n",
        "\n",
        "        m_hat = m / (1 - ADAM_BETA1 ** t)\n",
        "        v_hat = v / (1 - ADAM_BETA2 ** t)\n",
        "\n",
        "        # Update\n",
        "        param -= learning_rate * m_hat / (np.sqrt(v_hat) + ADAM_EPSILON)\n",
        "        return param, m, v\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: float, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass to compute gradients and update weights using Adam.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer, shape (batch_size, out_length, depth).\n",
        "        :param learning_rate: Learning rate for the optimizer.\n",
        "        :param kwargs: Expected to contain 't' (Adam timestep).\n",
        "        :return: Gradient with respect to the input of this layer.\n",
        "        \"\"\"\n",
        "        if 't' not in kwargs:\n",
        "            raise ValueError(\"Adam timestep 't' is required for backward pass.\")\n",
        "        t = kwargs['t']\n",
        "\n",
        "        batch_size = output_gradient.shape[0]\n",
        "        kernels_gradient = np.zeros_like(self.kernels)\n",
        "        biases_gradient = np.zeros_like(self.biases)\n",
        "\n",
        "        # Create input_gradient with float dtype explicitly\n",
        "        input_gradient = np.zeros_like(self.input, dtype=np.float64)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for d in range(self.depth):\n",
        "                biases_gradient[d] += np.sum(output_gradient[i, :, d])\n",
        "\n",
        "                for c in range(self.input_channels):\n",
        "                    input_slice = self.input[i, :, c]\n",
        "                    output_grad_slice = output_gradient[i, :, d]\n",
        "\n",
        "                    # Cross-correlation for weight gradient\n",
        "                    kernels_gradient[:, c, d] += scipy.signal.correlate(\n",
        "                        input_slice, output_grad_slice, mode='valid'\n",
        "                    )\n",
        "\n",
        "                    # Convolution for input gradient\n",
        "                    kernel_slice = self.kernels[:, c, d]\n",
        "                    # Flip the kernel for convolution (equivalent to rotation in 1D)\n",
        "                    flipped_kernel = np.flip(kernel_slice)\n",
        "                    input_gradient[i, :, c] += scipy.signal.convolve(\n",
        "                        output_grad_slice, flipped_kernel, mode='full'\n",
        "                    )\n",
        "\n",
        "        # Update kernels and biases using Adam\n",
        "        self.kernels, self.m_kernels, self.v_kernels = self._adam_update(\n",
        "            self.kernels, kernels_gradient, self.m_kernels, self.v_kernels, learning_rate, t\n",
        "        )\n",
        "        self.biases, self.m_biases, self.v_biases = self._adam_update(\n",
        "            self.biases, biases_gradient, self.m_biases, self.v_biases, learning_rate, t\n",
        "        )\n",
        "\n",
        "        return input_gradient\n",
        "\n",
        "\n",
        "class MaxPool2D(Layer):\n",
        "    \"\"\"2D Max Pooling Layer.\"\"\"\n",
        "    def __init__(self, pool_size: Tuple[int, int] = (2, 2), stride: Optional[Tuple[int, int]] = None):\n",
        "        \"\"\"\n",
        "        Initialize max pooling layer.\n",
        "\n",
        "        :param pool_size: Size of the pooling window (height, width).\n",
        "        :param stride: Step size for pooling. If None, defaults to pool_size.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.pool_height, self.pool_width = pool_size\n",
        "        self.stride_h, self.stride_w = stride if stride is not None else pool_size\n",
        "        self.max_indices: Optional[np.ndarray] = None\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the forward pass using max pooling.\n",
        "\n",
        "        :param input_data: Input data of shape (batch_size, height, width, channels).\n",
        "        :return: Output after max pooling.\n",
        "        \"\"\"\n",
        "        self.input = input_data\n",
        "        batch_size, h_in, w_in, channels = input_data.shape\n",
        "\n",
        "        h_out = (h_in - self.pool_height) // self.stride_h + 1\n",
        "        w_out = (w_in - self.pool_width) // self.stride_w + 1\n",
        "        if h_out <= 0 or w_out <= 0:\n",
        "            raise ValueError(f\"Pool size {self.pool_height, self.pool_width} with stride {self.stride_h, self.stride_w} \"\n",
        "                             f\"is too large for input shape {h_in, w_in}.\")\n",
        "\n",
        "        output = np.zeros((batch_size, h_out, w_out, channels))\n",
        "\n",
        "        self.max_indices = np.zeros((batch_size, h_out, w_out, channels, 2), dtype=int)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            for c in range(channels):\n",
        "                for i in range(h_out):\n",
        "                    for j in range(w_out):\n",
        "                        h_start = i * self.stride_h\n",
        "                        h_end = h_start + self.pool_height\n",
        "                        w_start = j * self.stride_w\n",
        "                        w_end = w_start + self.pool_width\n",
        "\n",
        "                        pool_region = input_data[b, h_start:h_end, w_start:w_end, c]\n",
        "\n",
        "                        max_val = np.max(pool_region)\n",
        "                        max_pos_relative = np.unravel_index(np.argmax(pool_region), pool_region.shape)\n",
        "\n",
        "                        output[b, i, j, c] = max_val\n",
        "                        self.max_indices[b, i, j, c] = max_pos_relative\n",
        "\n",
        "        self.output = output\n",
        "        return output\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: Optional[float] = None, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass for max pooling.\n",
        "\n",
        "        Distributes the gradient only to the locations where the max value was originally found.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer.\n",
        "        :param learning_rate: Not used for pooling layer.\n",
        "        :return: Gradient with respect to the input of this layer.\n",
        "        \"\"\"\n",
        "        if self.input is None or self.max_indices is None:\n",
        "            raise RuntimeError(\"Forward pass must be called before backward pass.\")\n",
        "\n",
        "        batch_size, h_out, w_out, channels = output_gradient.shape\n",
        "        input_gradient = np.zeros_like(self.input)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            for c in range(channels):\n",
        "                for i in range(h_out):\n",
        "                    for j in range(w_out):\n",
        "                      # Window Cordinates\n",
        "                        h_start = i * self.stride_h\n",
        "                        w_start = j * self.stride_w\n",
        "\n",
        "                        h_max_rel, w_max_rel = self.max_indices[b, i, j, c]\n",
        "\n",
        "                        h_abs = h_start + h_max_rel\n",
        "                        w_abs = w_start + w_max_rel\n",
        "\n",
        "                        input_gradient[b, h_abs, w_abs, c] += output_gradient[b, i, j, c]\n",
        "\n",
        "        return input_gradient\n",
        "\n",
        "\n",
        "class MaxPool1D(Layer):\n",
        "    \"\"\"1D Max Pooling layer for signal data like EEG.\"\"\"\n",
        "    def __init__(self, pool_size: int):\n",
        "        \"\"\"\n",
        "        Initialize 1D max pooling layer.\n",
        "\n",
        "        :param pool_size: Size of the pooling window.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._has_weights = False\n",
        "        self.pool_size = pool_size\n",
        "        if not isinstance(pool_size, int) or pool_size <= 0:\n",
        "            raise ValueError(\"pool_size must be a positive integer for MaxPool1D.\")\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the forward pass using max pooling operation.\n",
        "\n",
        "        :param input_data: Input data of shape (batch_size, length, channels).\n",
        "\n",
        "        :return: Output of shape (batch_size, new_length, channels).\n",
        "        \"\"\"\n",
        "        self.input = input_data\n",
        "        batch_size, input_length, channels = input_data.shape\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        output_length = (input_length - self.pool_size) // self.pool_size + 1\n",
        "\n",
        "        # Initialize output array and indices for backprop\n",
        "        output = np.zeros((batch_size, output_length, channels))\n",
        "        self.max_indices = np.zeros((batch_size, output_length, channels), dtype=int)\n",
        "\n",
        "        # Perform max pooling\n",
        "        for i in range(batch_size):\n",
        "            for c in range(channels):\n",
        "                for l in range(output_length):\n",
        "                    start_l = l * self.pool_size\n",
        "                    end_l = start_l + self.pool_size\n",
        "\n",
        "                    slice_1d = input_data[i, start_l:end_l, c]\n",
        "                    max_idx = np.argmax(slice_1d)\n",
        "                    output[i, l, c] = slice_1d[max_idx]\n",
        "\n",
        "                    # Store the index relative to the start of the window\n",
        "                    self.max_indices[i, l, c] = start_l + max_idx\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: Optional[float] = None, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer.\n",
        "        :param learning_rate: Not used for pooling layer.\n",
        "        :return: Gradient with respect to the input.\n",
        "        \"\"\"\n",
        "        batch_size, input_length, channels = self.input.shape\n",
        "        input_gradient = np.zeros_like(self.input)\n",
        "\n",
        "        # Get output dimensions\n",
        "        _, output_length, _ = output_gradient.shape\n",
        "\n",
        "        # Distribute gradients to the positions where the maximum was found\n",
        "        for i in range(batch_size):\n",
        "            for c in range(channels):\n",
        "                for l in range(output_length):\n",
        "                    idx = self.max_indices[i, l, c]\n",
        "                    input_gradient[i, idx, c] += output_gradient[i, l, c]\n",
        "\n",
        "        return input_gradient\n",
        "\n",
        "    def get_output_shape(self, input_shape=None) -> tuple:\n",
        "        \"\"\"\n",
        "        Calculate the output shape for this layer.\n",
        "\n",
        "        :param input_shape: Optional input shape tuple (length, channels).\n",
        "                           If None, uses the shape from the last forward pass.\n",
        "        :return: Output shape tuple (new_length, channels).\n",
        "        \"\"\"\n",
        "        if input_shape is None:\n",
        "            # Use the shape from the last forward pass\n",
        "            input_length = self.input.shape[1]\n",
        "            channels = self.input.shape[2]\n",
        "        else:\n",
        "            input_length, channels = input_shape\n",
        "\n",
        "        output_length = (input_length - self.pool_size) // self.pool_size + 1\n",
        "        return (output_length, channels)\n",
        "\n",
        "class Flatten(Layer):\n",
        "    \"\"\"Flattens the input volume into a vector.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.original_shape: Optional[Tuple[int, ...]] = None\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the forward pass, flattening the input.\n",
        "\n",
        "        :param input_data: Input data of shape (batch_size, height, width, channels) or similar.\n",
        "        :return: Flattened data of shape (batch_size, height * width * channels).\n",
        "        \"\"\"\n",
        "        self.input = input_data\n",
        "        self.original_shape = input_data.shape\n",
        "        batch_size = input_data.shape[0]\n",
        "\n",
        "        flattened_dim = np.prod(input_data.shape[1:])\n",
        "\n",
        "        self.output = input_data.reshape(batch_size, flattened_dim)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: Optional[float] = None, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass, reshaping the gradient back to the original input shape.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer (flattened).\n",
        "        :param learning_rate: Not used for flatten layer.\n",
        "        :return: Gradient with respect to the input (reshaped).\n",
        "        \"\"\"\n",
        "        if self.original_shape is None:\n",
        "             raise RuntimeError(\"Forward pass must be called before backward pass.\")\n",
        "\n",
        "        return output_gradient.reshape(self.original_shape)\n",
        "\n",
        "\n",
        "class Dense(Layer):\n",
        "    \"\"\"Dense (fully connected) layer.\"\"\"\n",
        "    def __init__(self, input_size: int, output_size: int):\n",
        "        \"\"\"\n",
        "        Initialize dense layer. Activation should be applied by a subsequent Activation layer.\n",
        "\n",
        "        :param input_size: Number of input features (neurons in the previous layer).\n",
        "        :param output_size: Number of output features (neurons in this layer).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._has_weights = True\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Xavier\n",
        "        limit = np.sqrt(6 / (input_size + output_size))\n",
        "        self.weights = np.random.uniform(-limit, limit, (input_size, output_size))\n",
        "        self.biases = np.zeros(output_size) # One bias per output neuron\n",
        "\n",
        "        # Adam\n",
        "        self.m_weights = np.zeros_like(self.weights)\n",
        "        self.v_weights = np.zeros_like(self.weights)\n",
        "        self.m_biases = np.zeros_like(self.biases)\n",
        "        self.v_biases = np.zeros_like(self.biases)\n",
        "\n",
        "\n",
        "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the forward pass (linear transformation Wx + b).\n",
        "\n",
        "        :param input_data: Input data of shape (batch_size, input_size).\n",
        "        :return: Output of shape (batch_size, output_size).\n",
        "        \"\"\"\n",
        "        self.input = input_data\n",
        "        self.output = np.dot(input_data, self.weights) + self.biases\n",
        "        return self.output\n",
        "\n",
        "    def _adam_update(self, param: np.ndarray, grad: np.ndarray, m: np.ndarray, v: np.ndarray,\n",
        "                     learning_rate: float, t: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"Helper function to perform Adam update.\"\"\"\n",
        "        m = ADAM_BETA1 * m + (1 - ADAM_BETA1) * grad\n",
        "        v = ADAM_BETA2 * v + (1 - ADAM_BETA2) * (grad ** 2)\n",
        "\n",
        "        m_hat = m / (1 - ADAM_BETA1 ** t)\n",
        "        v_hat = v / (1 - ADAM_BETA2 ** t)\n",
        "\n",
        "        # Update parameter\n",
        "        param -= learning_rate * m_hat / (np.sqrt(v_hat) + ADAM_EPSILON)\n",
        "        return param, m, v\n",
        "\n",
        "    def backward(self, output_gradient: np.ndarray, learning_rate: float, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform the backward pass for the dense layer using Adam optimizer.\n",
        "\n",
        "        Note: This gradient `output_gradient` is dL/dz where z is the output of this Dense layer\n",
        "              (BEFORE any activation is applied). It comes from the subsequent Activation layer's\n",
        "              backward pass.\n",
        "\n",
        "        :param output_gradient: Gradient from the next layer (typically an Activation layer).\n",
        "                                Shape: (batch_size, output_size).\n",
        "        :param learning_rate: Learning rate for the optimizer.\n",
        "        :param kwargs: Expected to contain 't' (Adam timestep).\n",
        "        :return: Gradient with respect to the input of this layer (dL/dx).\n",
        "                 Shape: (batch_size, input_size).\n",
        "        \"\"\"\n",
        "        if 't' not in kwargs:\n",
        "            raise ValueError(\"Adam timestep 't' is required for backward pass.\")\n",
        "        if self.input is None:\n",
        "             raise RuntimeError(\"Forward pass must be called before backward pass.\")\n",
        "        t = kwargs['t']\n",
        "\n",
        "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
        "\n",
        "        biases_gradient = np.sum(output_gradient, axis=0)\n",
        "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
        "        self.weights, self.m_weights, self.v_weights = self._adam_update(\n",
        "            self.weights, weights_gradient, self.m_weights, self.v_weights, learning_rate, t\n",
        "        )\n",
        "        self.biases, self.m_biases, self.v_biases = self._adam_update(\n",
        "            self.biases, biases_gradient, self.m_biases, self.v_biases, learning_rate, t\n",
        "        )\n",
        "\n",
        "        return input_gradient\n",
        "\n",
        "\n",
        "class CNN:\n",
        "    \"\"\"Convolutional Neural Network model.\"\"\"\n",
        "    def __init__(self, learning_rate: float = 0.001, loss: str = 'mse'):\n",
        "        \"\"\"\n",
        "        Initialize CNN model.\n",
        "\n",
        "        :param learning_rate: Learning rate for the Adam optimizer.\n",
        "        :param loss: Name of the loss function ('mse' or 'categorical_crossentropy').\n",
        "        \"\"\"\n",
        "        if loss not in LOSS_FUNCTIONS:\n",
        "            raise ValueError(f\"Unsupported loss function: '{loss}'. Supported: {list(LOSS_FUNCTIONS.keys())}\")\n",
        "\n",
        "        self.layers: List[Layer] = []\n",
        "        self.learning_rate = learning_rate\n",
        "        self.loss_func = LOSS_FUNCTIONS[loss]\n",
        "        self.loss_gradient_func = LOSS_GRADIENTS[loss]\n",
        "        self.loss_name = loss\n",
        "        self.t = 0\n",
        "\n",
        "    def add(self, layer: Layer):\n",
        "        \"\"\"Add a layer to the model.\"\"\"\n",
        "        if not isinstance(layer, Layer):\n",
        "            raise TypeError(\"Can only add objects derived from the Layer class.\")\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def predict(self, input_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Make predictions with the model.\n",
        "\n",
        "        :param input_data: Input data, shape depends on the first layer.\n",
        "                           (batch_size, height, width, channels) for Conv2D.\n",
        "                           (batch_size, features) for Dense.\n",
        "        :return: Model predictions, shape depends on the last layer.\n",
        "        \"\"\"\n",
        "\n",
        "        if input_data.ndim == 1:\n",
        "             input_data = np.expand_dims(input_data, axis=0)\n",
        "        elif input_data.ndim == 3 and isinstance(self.layers[0], Conv2D): # Single image\n",
        "             input_data = np.expand_dims(input_data, axis=0)\n",
        "\n",
        "        output = input_data\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(output)\n",
        "        return output\n",
        "\n",
        "    def train(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int, batch_size: int = 32, verbose: bool = True):\n",
        "        \"\"\"\n",
        "        Train the model using batches.\n",
        "\n",
        "        :param X_train: Training data.\n",
        "        :param y_train: Training labels (must match the output shape and loss function).\n",
        "                        For MSE/Sigmoid output: (n_samples, 1)\n",
        "                        For CCE/Softmax output: (n_samples, n_classes) (one-hot encoded).\n",
        "        :param epochs: Number of training epochs.\n",
        "        :param batch_size: Number of samples per gradient update.\n",
        "        :param verbose: Whether to print progress.\n",
        "        \"\"\"\n",
        "        n_samples = X_train.shape[0]\n",
        "\n",
        "        if n_samples == 0:\n",
        "             print(\"Warning: Training data is empty.\")\n",
        "             return\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            # Shuffle data at the beginning of each epoch\n",
        "            indices = np.random.permutation(n_samples)\n",
        "            X_shuffled = X_train[indices]\n",
        "            y_shuffled = y_train[indices]\n",
        "\n",
        "            for i in range(0, n_samples, batch_size):\n",
        "                X_batch = X_shuffled[i : min(i + batch_size, n_samples)]\n",
        "                y_batch = y_shuffled[i : min(i + batch_size, n_samples)]\n",
        "\n",
        "                if len(X_batch) == 0: continue\n",
        "\n",
        "                output = self.predict(X_batch)\n",
        "\n",
        "                epoch_loss += self.loss_func(y_batch, output) * len(X_batch)\n",
        "\n",
        "                self.t += 1\n",
        "                grad = self.loss_gradient_func(y_batch, output)\n",
        "                for layer in reversed(self.layers):\n",
        "                    adam_params = {}\n",
        "                    if layer.has_weights():\n",
        "                        adam_params = {'t': self.t}\n",
        "\n",
        "                    grad = layer.backward(grad, self.learning_rate, **adam_params)\n",
        "            average_epoch_loss = epoch_loss / n_samples\n",
        "\n",
        "            if verbose and (epoch % 10 == 0 or epoch == epochs - 1):\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {average_epoch_loss:.6f}\")\n",
        "\n",
        "    def save_model(self, filename: str):\n",
        "        \"\"\"Save the trained model to a file using pickle.\"\"\"\n",
        "\n",
        "        for layer in self.layers:\n",
        "            layer.input = None\n",
        "            layer.output = None\n",
        "            if isinstance(layer, MaxPool2D):\n",
        "                 layer.max_indices = None\n",
        "\n",
        "        try:\n",
        "            with open(filename, 'wb') as f:\n",
        "                pickle.dump(self, f)\n",
        "            print(f\"Model saved successfully to {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving model to {filename}: {e}\")\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, filename: str) -> 'CNN':\n",
        "        \"\"\"Load a model from a pickle file.\"\"\"\n",
        "        try:\n",
        "            with open(filename, 'rb') as f:\n",
        "                model = pickle.load(f)\n",
        "            if not isinstance(model, cls):\n",
        "                 raise TypeError(f\"Loaded object is not of type {cls.__name__}\")\n",
        "            print(f\"Model loaded successfully from {filename}\")\n",
        "\n",
        "            return model\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Model file not found at {filename}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model from {filename}: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "def load_and_preprocess_images(image_folder: str, target_size: Tuple[int, int]=(128, 128)) -> Tuple[np.ndarray,np.ndarray,Dict[str,int]]:\n",
        "    images=[]; labels=[]; class_to_index: Dict[str,int]={}; index_counter=0\n",
        "    if not os.path.isdir(image_folder): print(f\"Error: Folder not found: {image_folder}\"); return np.array([]),np.array([]),{}\n",
        "    contents=os.listdir(image_folder); subdirs=[i for i in contents if os.path.isdir(os.path.join(image_folder,i))]\n",
        "    if subdirs:\n",
        "        print(f\"Detected class subfolders: {', '.join(sorted(subdirs))}\")\n",
        "        for class_name in sorted(subdirs):\n",
        "            if class_name not in class_to_index: class_to_index[class_name]=index_counter; index_counter+=1\n",
        "            class_idx=class_to_index[class_name]; class_folder=os.path.join(image_folder,class_name)\n",
        "            for filename in os.listdir(class_folder):\n",
        "                if filename.lower().endswith(('.jpeg','.jpg','.png','.bmp','.gif')):\n",
        "                    img=cv2.imread(os.path.join(class_folder, filename))\n",
        "                    if img is None: print(f\" Warning: Could not load {filename}\"); continue\n",
        "                    if len(img.shape)==2: img=cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "                    else: img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "                    img_resized=cv2.resize(img,target_size)\n",
        "                    img_normalized=img_resized.astype(np.float32)/255.0\n",
        "                    images.append(img_normalized); labels.append(class_idx)\n",
        "    else:\n",
        "        print(f\"No subfolders found. Assuming single class 'class_0'.\")\n",
        "        class_name='class_0'; class_to_index[class_name]=0; class_idx=0\n",
        "        for filename in contents:\n",
        "            if filename.lower().endswith(('.jpeg','.jpg','.png','.bmp','.gif')):\n",
        "                 img=cv2.imread(os.path.join(image_folder,filename))\n",
        "                 if img is None: print(f\" Warning: Could not load {filename}\"); continue\n",
        "                 if len(img.shape)==2: img=cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "                 else: img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "                 img_resized=cv2.resize(img,target_size)\n",
        "                 img_normalized=img_resized.astype(np.float32)/255.0\n",
        "                 images.append(img_normalized); labels.append(class_idx)\n",
        "    if not images: print(\"Warning: No valid images loaded.\"); return np.array([]),np.array([]),{}\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "    return np.array(images), np.array(labels), class_to_index\n",
        "\n",
        "def visualize_predictions(\n",
        "    model: CNN,\n",
        "    images: np.ndarray,\n",
        "    true_labels: np.ndarray,\n",
        "    class_map: Dict[str, int],\n",
        "    num_samples: int = 5,\n",
        "    figsize: Tuple[int, int] = (15, 7)\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize model predictions alongside true labels for a few sample images.\n",
        "    Displays predicted label as 0 or 1 for binary classification.\n",
        "    Attempts to display float images directly.\n",
        "\n",
        "    :param model: The trained CNN model instance.\n",
        "    :param images: Array of images to predict on (preprocessed, float32, range [0,1]).\n",
        "    :param true_labels: Corresponding true labels (formatted, e.g., (N, 1) for binary).\n",
        "    :param class_map: Dictionary mapping class names (str) to integer indices (int).\n",
        "    :param num_samples: Number of random samples to display.\n",
        "    :param figsize: Figure size for the plot.\n",
        "    \"\"\"\n",
        "    num_total_images = images.shape[0]\n",
        "    if num_total_images == 0:\n",
        "        print(\"No images provided for visualization.\")\n",
        "        return\n",
        "\n",
        "    num_samples = min(num_samples, num_total_images)\n",
        "    if num_samples <= 0:\n",
        "         print(\"num_samples must be positive.\")\n",
        "         return\n",
        "\n",
        "    indices = np.random.choice(num_total_images, num_samples, replace=False)\n",
        "\n",
        "    index_to_class = {v: k for k, v in class_map.items()}\n",
        "\n",
        "    model_output_size = None\n",
        "    for layer in reversed(model.layers):\n",
        "        if hasattr(layer, 'output_size') and layer.output_size is not None:\n",
        "            model_output_size = layer.output_size\n",
        "            break\n",
        "    if model_output_size is None:\n",
        "        try: model_output_size=model.predict(np.expand_dims(images[0],axis=0)).shape[1]\n",
        "        except Exception as e: print(f\"Error inferring output size: {e}\"); return\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=figsize)\n",
        "    if num_samples == 1: axes = [axes]\n",
        "\n",
        "    print(f\"\\nVisualizing {num_samples} sample predictions...\")\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img = images[idx]\n",
        "        true_label_raw = true_labels[idx]\n",
        "\n",
        "        if img is None or img.size == 0 or np.isnan(img).any() or np.isinf(img).any():\n",
        "             print(f\"Warning: Invalid image data detected for sample index {idx}. Skipping.\")\n",
        "             axes[i].set_title(f\"Invalid Image\\nIndex {idx}\")\n",
        "             try: # Attempt to show a gray placeholder\n",
        "                 placeholder_shape = (target_size[0], target_size[1], 3) if 'target_size' in locals() else (96, 96, 3)\n",
        "                 axes[i].imshow(np.ones(placeholder_shape) * 0.5)\n",
        "             except Exception: pass\n",
        "             axes[i].axis('off')\n",
        "             continue\n",
        "\n",
        "        try:\n",
        "            prediction_output = model.predict(np.expand_dims(img, axis=0))\n",
        "            prediction = prediction_output[0]\n",
        "        except Exception as e:\n",
        "             print(f\"Error predicting sample {idx}: {e}\")\n",
        "             axes[i].set_title(f\"Prediction Error\\nIndex {idx}\")\n",
        "             axes[i].imshow(np.ones_like(img)*0.5) # Grey-scaling\n",
        "             axes[i].axis('off')\n",
        "             continue\n",
        "\n",
        "\n",
        "        pred_idx, true_idx, conf = -1, -1, 0.0\n",
        "        try:\n",
        "            if model_output_size == 1: # Binary CNN model used\n",
        "                conf = prediction[0]; pred_idx = 1 if conf > 0.5 else 0\n",
        "                conf = conf if pred_idx == 1 else 1 - conf; true_idx = int(true_label_raw[0])\n",
        "            elif model_output_size > 1: # Multi-class CNN model..\n",
        "                pred_idx = np.argmax(prediction); conf = prediction[pred_idx]; true_idx = np.argmax(true_label_raw)\n",
        "            else: raise ValueError(\"Invalid model output size\")\n",
        "            pred_lbl=str(pred_idx); true_lbl=str(true_idx)\n",
        "        except Exception as e:\n",
        "             print(f\"Error interpreting labels/predictions for sample {idx}: {e}\")\n",
        "             axes[i].set_title(f\"Label Error\\nIndex {idx}\")\n",
        "             axes[i].imshow(np.ones_like(img)*0.5)\n",
        "             axes[i].axis('off')\n",
        "             continue\n",
        "\n",
        "        try:\n",
        "            img_to_show = np.clip(img, 0.0, 1.0)\n",
        "            axes[i].imshow(img_to_show)\n",
        "            title = f\"True: {true_lbl}\\nPred: {pred_lbl} (Conf: {conf:.2f})\" # Attach the headinf\n",
        "            axes[i].set_title(title)\n",
        "\n",
        "            # Add colored Frames to each image after the drawings..\n",
        "            is_correct = (pred_idx == true_idx)\n",
        "            frame_color = 'green' if is_correct else 'red'\n",
        "            for spine in axes[i].spines.values():\n",
        "                spine.set_edgecolor(frame_color)\n",
        "                spine.set_linewidth(2.5)\n",
        "            axes[i].set_xticks([])\n",
        "            axes[i].set_yticks([])\n",
        "\n",
        "        except Exception as display_error:\n",
        "            print(f\"Error displaying image {idx}: {display_error}\")\n",
        "            axes[i].set_title(f\"Display Error\\nIndex {idx}\")\n",
        "            try: axes[i].imshow(np.ones_like(img) * 0.5) # Fallback gray-scaling..\n",
        "            except: pass\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        # If the prediction is correct then Border the picture with green, else red..\n",
        "        # This is done twice intentionally\n",
        "        is_correct = (pred_idx == true_idx); border_color = (0,1,0) if is_correct else (1,0,0)\n",
        "        img_display = (img*255).astype(np.uint8); border_val=[int(c*255) for c in border_color]\n",
        "        try: bordered_img = cv2.copyMakeBorder(img_display,5,5,5,5,cv2.BORDER_CONSTANT,value=border_val)\n",
        "        except: bordered_img = img_display\n",
        "        axes[i].imshow(bordered_img); axes[i].set_title(f\"True: {true_lbl}\\nPred: {pred_lbl} (Conf: {conf:.2f})\"); axes[i].axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def load_and_preprocess_eeg(file_path: str, n_channels: int, normalize: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Load and preprocess EEG data from a file.\n",
        "\n",
        "    :param file_path: Path to the EEG data file (e.g., .npy, .csv)\n",
        "    :param n_channels: Number of EEG channels in the data\n",
        "    :param normalize: Whether to normalize the data\n",
        "    :return: Preprocessed EEG data\n",
        "    \"\"\"\n",
        "    # Load data based on file extension\n",
        "    if file_path.endswith('.npy'):\n",
        "        data = np.load(file_path)\n",
        "    elif file_path.endswith('.csv'):\n",
        "        data = np.loadtxt(file_path, delimiter=',')\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "\n",
        "    # Reshape if needed (assuming data is in time points × channels)\n",
        "    if len(data.shape) == 2:\n",
        "        # Already in the right format\n",
        "        pass\n",
        "    elif len(data.shape) == 1:\n",
        "        # Single channel or flattened, reshape\n",
        "        data = data.reshape(-1, 1)\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected data shape: {data.shape}\")\n",
        "\n",
        "    # Check if number of channels matches\n",
        "    if data.shape[1] != n_channels:\n",
        "        raise ValueError(f\"Expected {n_channels} channels but got {data.shape[1]}\")\n",
        "\n",
        "    # Normalize if requested\n",
        "    if normalize:\n",
        "        # Normalize each channel separately\n",
        "        for c in range(n_channels):\n",
        "            channel_data = data[:, c]\n",
        "            # Skip normalization if channel is all zeros\n",
        "            if np.std(channel_data) > 0:\n",
        "                data[:, c] = (channel_data - np.mean(channel_data)) / np.std(channel_data)\n",
        "\n",
        "    # Add batch dimension for model input\n",
        "    data = np.expand_dims(data, axis=0)\n",
        "\n",
        "    return data\n",
        "\n",
        "def visualize_eeg(eeg_data: np.ndarray, predictions=None, channel_names=None, sampling_rate=250):\n",
        "    \"\"\"\n",
        "    Visualize EEG data with optional prediction results.\n",
        "\n",
        "    :param eeg_data: EEG data array of shape (samples, channels) or (batch, samples, channels)\n",
        "    :param predictions: Optional model predictions\n",
        "    :param channel_names: Optional list of channel names\n",
        "    :param sampling_rate: Sampling rate in Hz\n",
        "    \"\"\"\n",
        "    if len(eeg_data.shape) == 3:\n",
        "        eeg_data = eeg_data[0]  # Take the first sample if batched\n",
        "\n",
        "    n_channels = eeg_data.shape[1]\n",
        "    n_samples = eeg_data.shape[0]\n",
        "\n",
        "    # Create time axis\n",
        "    time = np.arange(n_samples) / sampling_rate\n",
        "\n",
        "    # Create plot\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i in range(n_channels):\n",
        "        plt.subplot(n_channels, 1, i+1)\n",
        "        plt.plot(time, eeg_data[:, i])\n",
        "\n",
        "        channel_label = f\"Channel {i}\" if channel_names is None else channel_names[i]\n",
        "        plt.ylabel(channel_label)\n",
        "\n",
        "        if i == 0:\n",
        "            plt.title(\"EEG Signal Visualization\")\n",
        "        if i == n_channels - 1:\n",
        "            plt.xlabel(\"Time (s)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # If predictions are provided, create a separate plot\n",
        "    if predictions is not None:\n",
        "        plt.figure(figsize=(8, 4))\n",
        "\n",
        "        if isinstance(predictions, np.ndarray) and len(predictions.shape) > 1:\n",
        "            # Multi-class case\n",
        "            class_probabilities = predictions[0]\n",
        "            plt.bar(range(len(class_probabilities)), class_probabilities)\n",
        "            plt.xlabel(\"Class Index\")\n",
        "            plt.ylabel(\"Probability\")\n",
        "            plt.title(f\"Model Predictions (Class {np.argmax(predictions)})\")\n",
        "        else:\n",
        "            # Binary case\n",
        "            plt.bar([\"Negative\", \"Positive\"], [1-predictions[0], predictions[0]])\n",
        "            plt.ylabel(\"Probability\")\n",
        "            plt.title(f\"Model Prediction: {predictions[0]:.3f}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def create_eeg_cnn(input_shape: Tuple[int, int], num_classes: int) -> CNN:\n",
        "    \"\"\"\n",
        "    Creates a CNN architecture for EEG data classification.\n",
        "\n",
        "    :param input_shape: Input shape (time_points, channels)\n",
        "    :param num_classes: Number of output classes\n",
        "    :return: An initialized CNN model instance\n",
        "    \"\"\"\n",
        "    time_points, channels = input_shape\n",
        "\n",
        "    if num_classes == 1:\n",
        "        output_activation = 'sigmoid'\n",
        "        loss_function = 'mse'\n",
        "        print(\"Configuring model for Binary Classification. Output: Sigmoid, Loss: MSE\")\n",
        "    elif num_classes > 1:\n",
        "        output_activation = 'softmax'\n",
        "        loss_function = 'categorical_crossentropy'\n",
        "        print(f\"Configuring model for Multi-class Classification. Output: Softmax, Loss: Categorical Crossentropy\")\n",
        "    else:\n",
        "        raise ValueError(\"num_classes must be >= 1\")\n",
        "\n",
        "    model = CNN(learning_rate=0.001, loss=loss_function)\n",
        "\n",
        "    # First convolutional block\n",
        "    k1_size, k1_depth = 8, 16  # Kernel size appropriate for EEG\n",
        "    model.add(Conv1D(input_shape=input_shape, kernel_size=k1_size, depth=k1_depth))\n",
        "    model.add(Activation('relu'))\n",
        "    pool1_size = 2\n",
        "    model.add(MaxPool1D(pool_size=pool1_size))\n",
        "\n",
        "    # Calculate shape after first block\n",
        "    time1_conv = time_points - k1_size + 1\n",
        "    time1_pool = time1_conv // pool1_size\n",
        "    shape1_out = (time1_pool, k1_depth)\n",
        "    print(f\"Shape after Block 1: {shape1_out}\")\n",
        "\n",
        "    # Second convolutional block\n",
        "    k2_size, k2_depth = 6, 32\n",
        "    model.add(Conv1D(input_shape=shape1_out, kernel_size=k2_size, depth=k2_depth))\n",
        "    model.add(Activation('relu'))\n",
        "    pool2_size = 2\n",
        "    model.add(MaxPool1D(pool_size=pool2_size))\n",
        "\n",
        "    # Calculate shape after second block\n",
        "    time2_conv = time1_pool - k2_size + 1\n",
        "    time2_pool = time2_conv // pool2_size\n",
        "    shape2_out = (time2_pool, k2_depth)\n",
        "    print(f\"Shape after Block 2: {shape2_out}\")\n",
        "\n",
        "    # Flatten and dense layers\n",
        "    model.add(Flatten())\n",
        "    flattened_size = time2_pool * k2_depth\n",
        "\n",
        "    dense1_units = 64\n",
        "    model.add(Dense(input_size=flattened_size, output_size=dense1_units))\n",
        "    model.add(Activation('relu'))\n",
        "    print(f\"Shape after Dense + ReLU: ({dense1_units},)\")\n",
        "\n",
        "    model.add(Dense(input_size=dense1_units, output_size=num_classes))\n",
        "    model.add(Activation(output_activation))\n",
        "    print(f\"Final output shape: ({num_classes},)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "SAVED_MODEL_PATH = 'brain_tumor_cnn.pkl'\n",
        "TEST_DATA_FOLDER = '/content/drive/MyDrive/Colab Notebooks/brain_tumor_dataset/Test' # Path to the new Testing Dataset... mAKe sure its new dataset and not repeated...\n",
        "TARGET_IMAGE_SIZE = (96, 96) # target size ~ Should be as same as onw used during training\n",
        "NUM_SAMPLES_TO_VISUALIZE = 8\n",
        "\n",
        "# Loading the Modle\n",
        "print(\"--- Loading Model ---\")\n",
        "model = None # Model Dummy Variable...\n",
        "if not os.path.exists(SAVED_MODEL_PATH):\n",
        "    print(f\"ERROR: Model file not found at '{SAVED_MODEL_PATH}'\")\n",
        "else:\n",
        "    try:\n",
        "        ###\n",
        "        model = CNN.load_model(SAVED_MODEL_PATH)\n",
        "        if model is None: raise ValueError(\"load_model returned None\")\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to load the model.\")\n",
        "        print(f\"Error details: {e}\")\n",
        "        print(\"Ensure class definitions (CNN, Layer, Conv2D, etc.) are defined in this cell or previous cells.\")\n",
        "\n",
        "\n",
        "def train_model_with_images(\n",
        "    image_folder: str,\n",
        "    target_size: Tuple[int, int] = (128, 128),\n",
        "    test_size: float = 0.2,\n",
        "    epochs: int = 10,\n",
        "    batch_size: int = 32,\n",
        "    model_save_path: Optional[str] = None\n",
        ") -> Optional[CNN]:\n",
        "    \"\"\"\n",
        "    Load images, create/train a CNN model, evaluate it, and optionally save it.\n",
        "\n",
        "    :param image_folder: Path to the folder containing images (structured or flat).\n",
        "    :param target_size: Target image size for preprocessing.\n",
        "    :param test_size: Proportion of data for the test set (used for internal validation).\n",
        "    :param epochs: Number of training epochs.\n",
        "    :param batch_size: Batch size for training.\n",
        "    :param model_save_path: Path to save the trained model. If None, model is not saved.\n",
        "    :return: The trained CNN model object, or None if training failed or no data was found.\n",
        "    \"\"\"\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Loading images from: {image_folder}\")\n",
        "    #\n",
        "    X, y, class_to_index = load_and_preprocess_images(image_folder, target_size)\n",
        "\n",
        "    if len(X) == 0:\n",
        "        print(\"Error: No images loaded. Aborting training.\")\n",
        "        return None\n",
        "\n",
        "    input_shape = X.shape[1:] # (height, width, channels)\n",
        "    num_samples = X.shape[0]\n",
        "    num_classes = len(class_to_index)\n",
        "    index_to_class = {v: k for k, v in class_to_index.items()} # For potential later use\n",
        "\n",
        "    print(f\"Found {num_samples} images belonging to {num_classes} classes.\")\n",
        "    print(f\"Input shape: {input_shape}\")\n",
        "    print(f\"Class map: {class_to_index}\")\n",
        "\n",
        "    y_processed = None\n",
        "    stratify_labels = None\n",
        "    if num_classes == 1: # Treat as binary (0 vs hypothetical 1) or single output regression\n",
        "        print(\"Warning: Only one class detected. Model output will be single value.\")\n",
        "        y_processed = y.reshape(-1, 1).astype(np.float32)\n",
        "        stratify_labels = y\n",
        "    elif num_classes == 2: # Binary classification\n",
        "        print(\"Preparing labels for Binary Classification.\")\n",
        "        y_processed = y.reshape(-1, 1).astype(np.float32)\n",
        "        stratify_labels = y\n",
        "    else: # Multi-class classification\n",
        "        print(\"Preparing labels for Multi-class Classification (One-Hot Encoding).\")\n",
        "        y_onehot = np.zeros((num_samples, num_classes), dtype=np.float32)\n",
        "        y_onehot[np.arange(num_samples), y] = 1.0\n",
        "        y_processed = y_onehot\n",
        "        stratify_labels = y\n",
        "\n",
        "    print(f\"Splitting data (Internal Validation/Test size: {test_size * 100}%)\")\n",
        "    X_train, X_val, y_train, y_val = None, None, None, None # Initialize\n",
        "    try:\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y_processed, test_size=test_size, random_state=42, stratify=stratify_labels\n",
        "        )\n",
        "    except ValueError as e:\n",
        "         print(f\"Warning: Stratified split failed ({e}). Performing non-stratified split.\")\n",
        "         X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y_processed, test_size=test_size, random_state=42\n",
        "        )\n",
        "    except NameError:\n",
        "        print(\"ERROR: `train_test_split` not imported or available.\")\n",
        "        return None #\n",
        "    if X_train is None: return None #\n",
        "\n",
        "    print(f\"Training set size: {X_train.shape[0]}\")\n",
        "    print(f\"Validation set size: {X_val.shape[0]}\") #\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(\"Creating CNN model...\")\n",
        "    model_num_classes = 1 if num_classes <= 2 else num_classes\n",
        "    try:\n",
        "        model = create_dynamic_cnn(input_shape, num_classes=model_num_classes)\n",
        "    except NameError:\n",
        "        print(\"ERROR: `create_dynamic_cnn` function is not defined.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating CNN model: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Starting training for {epochs} epochs with batch size {batch_size}...\")\n",
        "    try:\n",
        "        if not hasattr(model, 'train') or isinstance(getattr(model, 'train', None), type(NotImplementedError)):\n",
        "             print(\"ERROR: The `train` method is missing or not implemented in the CNN class definition.\")\n",
        "             return None\n",
        "        model.train(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=True)\n",
        "        print(\"Training finished.\")\n",
        "    except Exception as e:\n",
        "         print(f\"An error occurred during model.train(): {e}\")\n",
        "         return None # Training failed\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(\"Evaluating model on the internal validation set...\")\n",
        "    predictions = model.predict(X_val)\n",
        "\n",
        "    if model_num_classes == 1: # Binary or single-output case\n",
        "        pred_classes = (predictions > 0.5).astype(int)\n",
        "        true_classes = y_val.astype(int)\n",
        "        accuracy = np.mean(pred_classes == true_classes)\n",
        "        print(f\"Validation Accuracy (Binary @ 0.5): {accuracy * 100:.2f}%\")\n",
        "    else: # Multi-class case\n",
        "        pred_classes = np.argmax(predictions, axis=1)\n",
        "        true_classes = np.argmax(y_val, axis=1)\n",
        "        accuracy = np.mean(pred_classes == true_classes)\n",
        "        print(f\"Validation Accuracy (Multi-class): {accuracy * 100:.2f}%\")\n",
        "\n",
        "    if model_save_path:\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"Saving model to {model_save_path}...\")\n",
        "        try:\n",
        "            model.save_model(model_save_path)\n",
        "        except Exception as e:\n",
        "             print(f\"Error saving model: {e}\")\n",
        "    else:\n",
        "         print(\"Model not saved as no path was provided.\")\n",
        "\n",
        "    return model\n",
        "#Handle Training\n",
        "def run_training_pipeline(\n",
        "    image_folder: str,\n",
        "    target_size: Tuple[int, int],\n",
        "    test_split_ratio: float,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    default_model_name: str = \"brain_tumor_cnn.pkl\"\n",
        ") -> Optional[CNN]:\n",
        "    \"\"\"\n",
        "    Handles the complete training process from loading data to saving the model.\n",
        "\n",
        "    Args:\n",
        "        image_folder: Path to the training data folder (containing class subfolders).\n",
        "        target_size: Target image resize dimensions.\n",
        "        test_split_ratio: Fraction of data to use for internal validation split.\n",
        "        epochs: Number of training epochs.\n",
        "        batch_size: Training batch size.\n",
        "        default_model_name: Default filename for saving the model.\n",
        "\n",
        "    Returns:\n",
        "        The trained CNN model object, or None if training failed.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Training Pipeline ---\")\n",
        "\n",
        "    model_save_name = input(f\"Enter filename to save the trained model as [{default_model_name}]: \").strip()\n",
        "    if not model_save_name:\n",
        "        model_save_name = default_model_name\n",
        "    if not model_save_name.lower().endswith('.pkl'):\n",
        "        model_save_name += '.pkl'\n",
        "        print(f\"Added .pkl extension. Model will be saved as: {model_save_name}\")\n",
        "\n",
        "    print(f\"\\nTraining Configuration:\")\n",
        "    print(f\"  Dataset Folder: {image_folder}\")\n",
        "    print(f\"  Target Size: {target_size}\")\n",
        "    print(f\"  Epochs: {epochs}, Batch Size: {batch_size}\")\n",
        "    print(f\"  Model Save Path: {model_save_name}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        trained_model = train_model_with_images(\n",
        "            image_folder=image_folder,\n",
        "            target_size=target_size,\n",
        "            test_size=test_split_ratio,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            model_save_path=model_save_name\n",
        "        )\n",
        "\n",
        "        if trained_model:\n",
        "            print(f\"\\n--- Training Pipeline Completed Successfully ---\")\n",
        "            print(f\"Trained model saved to {model_save_name}\")\n",
        "            return trained_model\n",
        "        else:\n",
        "            print(\"\\n--- Model training failed or was aborted ---\")\n",
        "            return None\n",
        "    except NameError:\n",
        "         print(\"ERROR: `train_model_with_images` function is not defined.\")\n",
        "         print(\"Please ensure the training helper function is included in the script.\")\n",
        "         return None\n",
        "    except Exception as e:\n",
        "         print(f\"\\n--- An error occurred during training: ---\")\n",
        "         print(e)\n",
        "         return None\n",
        "\n",
        "\n",
        "def create_dynamic_cnn(input_shape: Tuple[int, int, int], num_classes: int) -> CNN:\n",
        "    \"\"\"\n",
        "    Creates a standard CNN architecture dynamically based on input shape and number of classes.\n",
        "\n",
        "    Architecture: Conv -> ReLU -> Pool -> Conv -> ReLU -> Pool -> Flatten -> Dense -> ReLU -> Dense -> Output Activation\n",
        "\n",
        "    :param input_shape: Input shape (height, width, channels).\n",
        "    :param num_classes: Number of output classes. Determines the final layer size and activation.\n",
        "                        If num_classes = 1, uses Sigmoid for binary classification.\n",
        "                        If num_classes > 1, uses Softmax for multi-class classification.\n",
        "    :return: An initialized CNN model instance.\n",
        "    \"\"\"\n",
        "    h, w, c = input_shape\n",
        "    model: Optional[CNN] = None\n",
        "\n",
        "    if num_classes == 1:\n",
        "        output_activation = 'sigmoid'\n",
        "        loss_function = 'mse'\n",
        "        print(\"Configuring model for Binary Classification (num_classes=1). Output: Sigmoid, Loss: MSE\")\n",
        "    elif num_classes > 1:\n",
        "        output_activation = 'softmax'\n",
        "        loss_function = 'categorical_crossentropy'\n",
        "        print(f\"Configuring model for Multi-class Classification (num_classes={num_classes}). Output: Softmax, Loss: Categorical Crossentropy\")\n",
        "    else:\n",
        "        raise ValueError(\"num_classes must be >= 1\")\n",
        "\n",
        "    model = CNN(learning_rate=0.001, loss=loss_function)\n",
        "    k1_size, k1_depth = (3, 3), 16\n",
        "    model.add(Conv2D(input_shape=input_shape, kernel_size=k1_size, depth=k1_depth))\n",
        "    model.add(Activation('relu'))\n",
        "    pool1_size = (2, 2)\n",
        "    model.add(MaxPool2D(pool_size=pool1_size))\n",
        "\n",
        "    h1_conv = h - k1_size[0] + 1\n",
        "    w1_conv = w - k1_size[1] + 1\n",
        "    h1_pool = (h1_conv - pool1_size[0]) // pool1_size[0] + 1\n",
        "    w1_pool = (w1_conv - pool1_size[1]) // pool1_size[1] + 1\n",
        "    shape1_out = (h1_pool, w1_pool, k1_depth)\n",
        "    print(f\"Shape after Layer 1 (Conv+ReLU+Pool): {shape1_out}\")\n",
        "\n",
        "    k2_size, k2_depth = (3, 3), 32\n",
        "    model.add(Conv2D(input_shape=shape1_out, kernel_size=k2_size, depth=k2_depth))\n",
        "    model.add(Activation('relu'))\n",
        "    pool2_size = (2, 2)\n",
        "    model.add(MaxPool2D(pool_size=pool2_size))\n",
        "    h2_conv = h1_pool - k2_size[0] + 1\n",
        "    w2_conv = w1_pool - k2_size[1] + 1\n",
        "    h2_pool = (h2_conv - pool2_size[0]) // pool2_size[0] + 1\n",
        "    w2_pool = (w2_conv - pool2_size[1]) // pool2_size[1] + 1\n",
        "    shape2_out = (h2_pool, w2_pool, k2_depth)\n",
        "    print(f\"Shape after Layer 2 (Conv+ReLU+Pool): {shape2_out}\")\n",
        "\n",
        "    model.add(Flatten())\n",
        "    flattened_size = h2_pool * w2_pool * k2_depth\n",
        "    if flattened_size <= 0:\n",
        "         raise ValueError(f\"Calculated flattened size is non-positive ({flattened_size}). Check intermediate shapes.\")\n",
        "    print(f\"Shape after Flatten: ({flattened_size},)\")\n",
        "\n",
        "    dense1_units = 128\n",
        "    model.add(Dense(input_size=flattened_size, output_size=dense1_units))\n",
        "    model.add(Activation('relu'))\n",
        "    print(f\"Shape after Dense 1 + ReLU: ({dense1_units},)\")\n",
        "\n",
        "    model.add(Dense(input_size=dense1_units, output_size=num_classes))\n",
        "    model.add(Activation(output_activation))\n",
        "    print(f\"Shape after Output Dense + Activation ({output_activation}): ({num_classes},)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_testing_pipeline(\n",
        "    model_load_path: str,\n",
        "    test_data_folder: str,\n",
        "    target_size: Tuple[int, int],\n",
        "    num_samples_to_visualize: int = 8\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a pre-trained model, test data, and performs visualization.\n",
        "\n",
        "    Args:\n",
        "        model_load_path: Path to the saved .pkl model file.\n",
        "        test_data_folder: Path to the separate test dataset folder.\n",
        "        target_size: Target image resize dimensions (must match training).\n",
        "        num_samples_to_visualize: Number of samples to show in visualization.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Testing & Visualization Pipeline ---\")\n",
        "    print(f\"Attempting to load model: {model_load_path}\")\n",
        "    print(f\"Using Test Data from: {test_data_folder}\")\n",
        "    print(f\"Expected Target Size: {target_size}\")\n",
        "\n",
        "    model = None\n",
        "    if not os.path.exists(model_load_path):\n",
        "        print(f\"ERROR: Model file not found at '{model_load_path}'\")\n",
        "        return # Exit this function if model not found\n",
        "    try:\n",
        "        model = CNN.load_model(model_load_path)\n",
        "        if model is None: raise ValueError(\"load_model returned None\")\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except NameError:\n",
        "         print(\"ERROR: `CNN` class or its dependencies not defined.\")\n",
        "         print(\"Please ensure all class definitions are included before this call.\")\n",
        "         return\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to load the model: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    test_images, test_labels_formatted, class_map = None, None, None\n",
        "    print(\"\\n--- Loading Test Data ---\")\n",
        "    if not os.path.isdir(test_data_folder):\n",
        "        print(f\"ERROR: Test data directory not found at '{test_data_folder}'\")\n",
        "    else:\n",
        "        try:\n",
        "            # The try Catch block is for ensuring that every element in here is defined.. Catch the error if not defnined.\n",
        "            test_images, test_label_indices, class_map = load_and_preprocess_images(test_data_folder, target_size)\n",
        "            if len(test_images) == 0:\n",
        "                print(\"ERROR: No images loaded from the test directory.\")\n",
        "            else:\n",
        "                print(f\"Loaded {len(test_images)} test images.\")\n",
        "                print(f\"Class map: {class_map}\")\n",
        "                # Fomart the true labels\n",
        "                num_classes = len(class_map)\n",
        "                if num_classes <= 2: # Binary case\n",
        "                    test_labels_formatted = test_label_indices.reshape(-1, 1).astype(np.float32)\n",
        "                    print(\"Labels formatted for binary visualization.\")\n",
        "                else: # Multi-class case\n",
        "                    test_labels_formatted = np.zeros((len(test_label_indices), num_classes), dtype=np.float32)\n",
        "                    test_labels_formatted[np.arange(len(test_label_indices)), test_label_indices] = 1.0\n",
        "                    print(\"Labels formatted for multi-class visualization (one-hot).\")\n",
        "        except NameError:\n",
        "            print(\"ERROR: `load_and_preprocess_images` function is not defined.\")\n",
        "            test_images = None # Mark as failed\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Failed to load or preprocess test data: {e}\")\n",
        "            test_images = None # Mark as failed\n",
        "\n",
        "    if test_images is not None and test_labels_formatted is not None and class_map:\n",
        "        print(\"\\n--- Visualizing Predictions ---\")\n",
        "        try: # Ensure tat the visualisation information is defined properly ..\n",
        "            visualize_predictions(\n",
        "                model=model,\n",
        "                images=test_images,\n",
        "                true_labels=test_labels_formatted,\n",
        "                class_map=class_map,\n",
        "                num_samples=num_samples_to_visualize,\n",
        "                figsize=(15, 7)\n",
        "            )\n",
        "        except NameError:\n",
        "             print(\"ERROR: `visualize_predictions` function is not defined.\")\n",
        "        except Exception as e:\n",
        "             print(f\"ERROR: An error occurred during visualization: {e}\")\n",
        "    else:\n",
        "        print(\"\\nSkipping visualization due to errors in loading data.\")\n",
        "\n",
        "    print(\"\\n--- Testing/Visualization Pipeline Finished ---\")\n",
        "def Image_Menu():\n",
        "  TRAIN_IMAGE_FOLDER = '/content/drive/MyDrive/Colab Notebooks/brain_tumor_dataset/Train'\n",
        "  TEST_IMAGE_FOLDER = '/content/drive/MyDrive/Colab Notebooks/brain_tumor_dataset/Test'\n",
        "  TARGET_SIZE = (96, 96)\n",
        "  # This is when you are using the google colab, Ensure that\n",
        "  DEFAULT_MODEL_NAME = '/content/drive/MyDrive/Colab Notebooks/brain_tumor_dataset/Model Versions/brain_tumor_cnn.pkl'\n",
        "    # If running the file locally, Use the following pATHS..\n",
        "    # DEFAULT_MODEL_NAME = '/Assets/Models/brain_tumor_cnn.pkl'\n",
        "    # For the online dataset, Need to try Online\n",
        "\n",
        "\n",
        "\n",
        "  TEST_SPLIT_RATIO = 0.2\n",
        "  EPOCHS = 15\n",
        "  BATCH_SIZE = 16\n",
        "  NUM_SAMPLES_TO_VISUALIZE = 8\n",
        "\n",
        "    # Check if the training folder exists\n",
        "  if not os.path.isdir(TRAIN_IMAGE_FOLDER):\n",
        "      print(f\"!!! CRITICAL ERROR: Training data folder not found at:\")\n",
        "      print(f\"!!! {TRAIN_IMAGE_FOLDER}\")\n",
        "      print(\"!!! Please ensure the path is correct and data is accessible.\")\n",
        "      exit()\n",
        "\n",
        "    # User -\n",
        "  mode = \"\"\n",
        "  while mode.lower() not in ['train', 'test']:\n",
        "      mode = input(\"Do you want to 'train' a new model or 'test' an existing one? (train/test): \").lower().strip()\n",
        "      if mode not in ['train', 'test']:\n",
        "          print(\"Invalid input. Please enter 'train' or 'test'.\")\n",
        "\n",
        "    # --- Execute Chosen Mode ---\n",
        "  if mode == 'train':\n",
        "        # Ensure train_model_with_images function is defined before calling run_training_pipeline\n",
        "      run_training_pipeline(\n",
        "          image_folder=TRAIN_IMAGE_FOLDER,\n",
        "          target_size=TARGET_SIZE,\n",
        "          test_split_ratio=TEST_SPLIT_RATIO,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          default_model_name=DEFAULT_MODEL_NAME\n",
        "\n",
        "          )\n",
        "\n",
        "  elif mode == 'test':\n",
        "        # User Promptig to give Give options\n",
        "      model_load_name = input(f\"Enter the filename of the pre-trained model to load [{DEFAULT_MODEL_NAME}]: \").strip()\n",
        "      if not model_load_name:\n",
        "          model_load_name = DEFAULT_MODEL_NAME\n",
        "      if not model_load_name.lower().endswith('.pkl'):\n",
        "          model_load_name += '.pkl'\n",
        "          print(f\"Added .pkl extension. Loading: {model_load_name}\")\n",
        "\n",
        "        # Check if the specified model file exists BEFORE calling\n",
        "      if not os.path.exists(model_load_name):\n",
        "          print(\"-\" * 50)\n",
        "          print(f\"ERROR: Pre-trained model file '{model_load_name}' not found.\")\n",
        "          retry_train = input(\"Would you like to try training a model instead? (yes/no): \").lower().strip()\n",
        "          if retry_train == 'yes':\n",
        "                # Ensure train_model_with_images function is defined\n",
        "                run_training_pipeline(\n",
        "                  image_folder=TRAIN_IMAGE_FOLDER,\n",
        "                  target_size=TARGET_SIZE,\n",
        "                  test_split_ratio=TEST_SPLIT_RATIO,\n",
        "                  epochs=EPOCHS,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                    default_model_name=DEFAULT_MODEL_NAME # Use default name if training now\n",
        "                )\n",
        "          else:\n",
        "                print(\"Exiting.\")\n",
        "      else:\n",
        "            # Model file exists, Test the mods..\n",
        "            run_testing_pipeline(\n",
        "                model_load_path=model_load_name,\n",
        "                test_data_folder=TEST_IMAGE_FOLDER,\n",
        "                target_size=TARGET_SIZE,\n",
        "                num_samples_to_visualize=NUM_SAMPLES_TO_VISUALIZE\n",
        "            )\n",
        "\n",
        "      print(\"\\n--- Script Finished ---\")\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_eeg(X, fs=174.0):\n",
        "    \"\"\"\n",
        "    Comprehensive EEG preprocessing\n",
        "\n",
        "    :param X: EEG data of shape (samples, sequence_length, channels)\n",
        "    :param fs: Sampling frequency in Hz\n",
        "    :return: Preprocessed EEG data\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing EEG data...\")\n",
        "    X_processed = X.copy().astype(np.float64)\n",
        "\n",
        "    # 1. Apply highpass filter to remove DC offset (drift)\n",
        "    b, a = scipy.signal.butter(4, 0.5/fs*2, 'highpass')\n",
        "    for i in range(X.shape[0]):\n",
        "        for c in range(X.shape[2]):\n",
        "            X_processed[i, :, c] = scipy.signal.filtfilt(b, a, X_processed[i, :, c])\n",
        "\n",
        "    # 2. Apply notch filter to remove line noise (50/60 Hz)\n",
        "    b, a = scipy.signal.iirnotch(60, 30, fs)\n",
        "    for i in range(X.shape[0]):\n",
        "        for c in range(X.shape[2]):\n",
        "            X_processed[i, :, c] = scipy.signal.filtfilt(b, a, X_processed[i, :, c])\n",
        "\n",
        "    # 3. Z-score normalization\n",
        "    for i in range(X.shape[0]):\n",
        "        for c in range(X.shape[2]):\n",
        "            mean_val = np.mean(X_processed[i, :, c])\n",
        "            std_val = np.std(X_processed[i, :, c])\n",
        "            # Avoid division by zero\n",
        "            if std_val > 0:\n",
        "                X_processed[i, :, c] = (X_processed[i, :, c] - mean_val) / std_val\n",
        "\n",
        "    print(\"Preprocessing complete.\")\n",
        "    return X_processed\n",
        "\n",
        "\n",
        "\n",
        "def load_epilepsy_data(csv_path='/content/drive/MyDrive/Colab Notebooks/eeg_data/Epileptic Seizure Recognition.csv'):\n",
        "    \"\"\"Process epilepsy dataset from Kaggle with enhanced preprocessing\"\"\"\n",
        "    print(f\"Loading data from {csv_path}...\")\n",
        "\n",
        "    # Load CSV file\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Convert data to proper format\n",
        "    X = np.array(df.iloc[:, 1:179]).astype(np.float64)  # Convert to float64\n",
        "    y = np.array(df.iloc[:, -1])     # Labels (1-5)\n",
        "\n",
        "    # Reshape for Conv1D: (samples, sequence_length, channels)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "    # Apply preprocessing\n",
        "    X = preprocess_eeg(X)\n",
        "\n",
        "    # Convert labels (1=seizure, 2-5=non-seizure)\n",
        "    y = np.where(y == 1, 1, 0)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    y_onehot = np.zeros((y.size, 2))\n",
        "    y_onehot[np.arange(y.size), y] = 1\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_onehot, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    print(f\"Data loaded: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "def optimize_computation():\n",
        "    \"\"\"Function to check and optimize computation resources\"\"\"\n",
        "    try:\n",
        "        # Try to import CuPy for GPU-accelerated NumPy operations\n",
        "        import cupy as cp\n",
        "        print(\"CuPy found! Using GPU acceleration for NumPy operations\")\n",
        "\n",
        "        # Replace numpy with cupy for key operations\n",
        "        global np\n",
        "        np_cpu = np  # Keep a reference to CPU numpy\n",
        "        np = cp  # Use cupy for acceleration\n",
        "\n",
        "        # Function to move data back to CPU when needed\n",
        "        def to_cpu(array):\n",
        "            if isinstance(array, cp.ndarray):\n",
        "                return cp.asnumpy(array)\n",
        "            return array\n",
        "\n",
        "        return True, to_cpu\n",
        "    except ImportError:\n",
        "        print(\"CuPy not found. Running on CPU only.\")\n",
        "        print(\"For GPU acceleration, install CuPy: pip install cupy-cuda11x\")\n",
        "        return False, lambda x: x\n",
        "def main():\n",
        "    # Initialize GPU acceleration if available\n",
        "    use_gpu, to_cpu = optimize_computation()\n",
        "    print(f\"GPU acceleration: {'Enabled' if use_gpu else 'Disabled'}\")\n",
        "\n",
        "    # Download dataset if needed\n",
        "    try:\n",
        "        if not os.path.exists('/content/drive/MyDrive/Colab Notebooks/eeg_data'):\n",
        "            print(\"Downloading dataset...\")\n",
        "            try:\n",
        "                import kagglehub\n",
        "                path = kagglehub.dataset_download(\"harunshimanto/epileptic-seizure-recognition\", \"eeg_data\")\n",
        "                print(f\"Dataset downloaded to: {path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading dataset: {e}\")\n",
        "                print(\"Please download manually from Kaggle\")\n",
        "    except:\n",
        "        print(\"Please manually download the dataset from Kaggle\")\n",
        "        print(\"https://www.kaggle.com/datasets/harunshimanto/epileptic-seizure-recognition\")\n",
        "        print(\"and place it in ./eeg_data/\")\n",
        "\n",
        "    # Load data\n",
        "    X_train, X_test, y_train, y_test = load_epilepsy_data()\n",
        "\n",
        "    # Transfer to GPU if using CuPy\n",
        "    if use_gpu:\n",
        "        try:\n",
        "            import cupy as cp\n",
        "            X_train = cp.array(X_train)\n",
        "            y_train = cp.array(y_train)\n",
        "            print(\"Data transferred to GPU\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error transferring data to GPU: {e}\")\n",
        "            use_gpu = False\n",
        "\n",
        "    # Set up model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    print(f\"Creating EEG model with input shape {input_shape}, {num_classes} classes\")\n",
        "    model = create_eeg_cnn(input_shape=input_shape, num_classes=num_classes)\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining model...\")\n",
        "    model.train(\n",
        "        X_train=X_train,\n",
        "        y_train=y_train,\n",
        "        epochs=30,\n",
        "        batch_size=64,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Move test data to GPU if needed\n",
        "    if use_gpu:\n",
        "        try:\n",
        "            import cupy as cp\n",
        "            X_test = cp.array(X_test)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Convert data back to CPU for evaluation if needed\n",
        "    if use_gpu:\n",
        "        X_test = to_cpu(X_test)\n",
        "        y_test = to_cpu(y_test)\n",
        "        predictions = to_cpu(predictions)\n",
        "\n",
        "    pred_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = np.argmax(y_test, axis=1)\n",
        "    accuracy = np.mean(pred_classes == true_classes)\n",
        "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Save model\n",
        "    model.save_model('eeg_epilepsy_model.pkl')\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(model, X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def visualize_results(model, X_test, y_test):\n",
        "    \"\"\"Visualize model performance\"\"\"\n",
        "    # Get predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    pred_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(true_classes, pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "\n",
        "    classes = ['Non-Seizure', 'Seizure']\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig('eeg_results_confusion.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(true_classes, pred_classes, target_names=classes))\n",
        "\n",
        "    # Plot sample EEG signals\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sample_idx = np.random.choice(len(X_test), 3)\n",
        "\n",
        "    for i, idx in enumerate(sample_idx):\n",
        "        plt.subplot(3, 1, i+1)\n",
        "        plt.plot(X_test[idx, :, 0])\n",
        "        plt.title(f\"Class: {'Seizure' if true_classes[idx]==1 else 'Non-Seizure'}, \" +\n",
        "                  f\"Predicted: {'Seizure' if pred_classes[idx]==1 else 'Non-Seizure'}\")\n",
        "        plt.tight_layout()\n",
        "\n",
        "    plt.savefig('eeg_sample_signals.png')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy"
      ],
      "metadata": {
        "id": "DtvLJwKzsYDp",
        "outputId": "30f09171-d5d3-4b6d-c7e6-0692ca782475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DtvLJwKzsYDp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy\n",
            "  Using cached cupy-13.4.1.tar.gz (3.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy) (0.8.3)\n",
            "Building wheels for collected packages: cupy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for cupy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cupy\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for cupy\n",
            "Failed to build cupy\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (cupy)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}