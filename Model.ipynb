{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivyson/Neural-Network-XOR/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "kpq-VL8HcwOU",
        "outputId": "55e67196-f7a3-420a-dc11-109c90e05076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.54\n",
            "Epoch 1000, Loss: 0.05\n",
            "Epoch 2000, Loss: 0.03\n",
            "Epoch 3000, Loss: 0.02\n",
            "Epoch 4000, Loss: 0.02\n",
            "Epoch 5000, Loss: 0.01\n",
            "Epoch 6000, Loss: 0.01\n",
            "Epoch 7000, Loss: 0.01\n",
            "Epoch 8000, Loss: 0.01\n",
            "Epoch 9000, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Model is too small and the learning rate is pretty quick\\nSo, The 50 Thousands epochs are not tha much of a deal,\\never since the model has to solve a basic problem\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self, input_size, hidden_nodes, output_size, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        :param input_size: Number of input neurons\n",
        "        :param hidden_nodes: List specifying number of neurons in each hidden layer\n",
        "        :param output_size: Number of output neurons\n",
        "        :param learning_rate: Learning rate for weight updates\n",
        "\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.hidden_nodes = hidden_nodes  # List specifying neurons per hidden layer\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Define the architecture: input layer → hidden layers → output layer\n",
        "        layer_sizes = [input_size] + hidden_nodes + [output_size]\n",
        "\n",
        "        # Initialize weights and biases dynamically\n",
        "        self.weights = [np.random.rand(layer_sizes[i], layer_sizes[i+1]) - 0.5 for i in range(len(layer_sizes) - 1)]\n",
        "        self.biases = [np.random.rand(layer_sizes[i+1]) - 0.5 for i in range(len(layer_sizes) - 1)]\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedForward(self, inputs):\n",
        "        # Forward propagation through all layers.......\n",
        "        self.layers = [inputs]  # Store activations of all layers\n",
        "        for i in range(len(self.weights)):\n",
        "            inputs = self.sigmoid(np.dot(inputs, self.weights[i]) + self.biases[i])\n",
        "            self.layers.append(inputs)  # Save outputs of [i+1] layer for backpropagation\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    # Back Prop, to update the weights and Biases of the nueral network\n",
        "    def backpropagation(self, target_output):\n",
        "        errors = [target_output - self.layers[-1]]  # Output layer error\n",
        "        deltas = [errors[0] * self.sigmoid_derivative(self.layers[-1])]  # Output layer delta\n",
        "\n",
        "        # Get Dltas For each hidden layer in reverse order\n",
        "        for i in range(len(self.hidden_nodes), 0, -1):\n",
        "            errors.insert(0, np.dot(deltas[0], self.weights[i].T))  # Error of previous layer\n",
        "            deltas.insert(0, errors[0] * self.sigmoid_derivative(self.layers[i]))  # Delta, previous layer\n",
        "\n",
        "        # Update weights and biases\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] += np.dot(self.layers[i].reshape(-1, 1), deltas[i].reshape(1, -1)) * self.learning_rate\n",
        "            self.biases[i] += deltas[i] * self.learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for i in range(len(X)):\n",
        "                self.feedForward(X[i])\n",
        "                self.backpropagation(y[i])\n",
        "                total_loss += np.sum(np.abs(y[i] - self.layers[-1]))\n",
        "\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {(total_loss / len(X)):.2f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.feedForward(x) for x in X]\n",
        "\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        with open(filename, 'wb') as file:\n",
        "            np.save(file, self.input_size)\n",
        "            np.save(file, self.hidden_nodes)\n",
        "            np.save(file, self.output_size)\n",
        "\n",
        "\n",
        "            # Save all weights and biases\n",
        "            for weight in self.weights:\n",
        "                np.save(file, weight)\n",
        "\n",
        "            for bias in self.biases:\n",
        "                np.save(file, bias)\n",
        "\n",
        "\n",
        "    def Load_Model(self, filename):\n",
        "      # Open the file in read mode\n",
        "      with open(filename, 'rb') as file:\n",
        "          self.input_size = int(np.load(file))\n",
        "          self.hidden_nodes = np.load(file)\n",
        "          self.output_size = int(np.load(file))\n",
        "          # Size of the weights = [len(inputs)*Hidden[0]][Hidden[0]*]\n",
        "          self.weights = []\n",
        "          self.biases = []\n",
        "          size = [self.input_size] + self.hidden_nodes + [self.output_size]\n",
        "          self.weights = [np.load(file) for _ in range(len(size) + 1)]\n",
        "          self.biases = [np.load(file) for _ in range(len(size) + 1)]\n",
        "          print(f'Biases : {self.biases}')\n",
        "          print(f'Weights : {self.weights}')\n",
        "          print(f'Input Size : {self.input_size}')\n",
        "          print(f'Hidden Nodes : {self.hidden_nodes}')\n",
        "          print(f'Output Size : {self.output_size} ')\n",
        "\n",
        "\n",
        "# OR dataset\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "#  Desired Output/ Target Output\n",
        "y = np.array([\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1]\n",
        "])\n",
        "\n",
        "# Create A Nueral Network with 2 inputs, and 2 Hidden Layers with nodes each,\n",
        "nn = NeuralNetwork(input_size=2, hidden_nodes=[20], output_size=1, learning_rate=0.2)\n",
        "nn.train(X, y, epochs=10000)\n",
        "\"\"\"\n",
        "The Model is too small and the learning rate is pretty quick\n",
        "So, The 50 Thousands epochs are not tha much of a deal,\n",
        "ever since the model has to solve a basic problem\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "Test = np.array([ # Feed the model randomised data to see the accuracy\n",
        "    [1, 1], # 1\n",
        "    [1, 0], # 1\n",
        "    [1, 1],  # 1\n",
        "    [0, 0]  # 0\n",
        "])\n",
        "# tEST PREDICTION\n",
        "predictions = np.round(nn.predict(Test))\n",
        "print(\"Predictions for OR function:\")\n",
        "for i in range(len(Test)):\n",
        "    print(f\"Input: {Test[i]} -> Predicted Output: {predictions[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo-pEO9tyMgA",
        "outputId": "e9bec583-ca92-4ded-8430-14eaee7c0005"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for OR function:\n",
            "Input: [1 1] -> Predicted Output: [1.]\n",
            "Input: [1 0] -> Predicted Output: [1.]\n",
            "Input: [1 1] -> Predicted Output: [1.]\n",
            "Input: [0 0] -> Predicted Output: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.save_model('model.txt')"
      ],
      "metadata": {
        "id": "p4l5ZgMoA1_m"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Load_Model('model.txt')"
      ],
      "metadata": {
        "id": "7iPCueRgDuPM",
        "outputId": "abff2525-d055-44a0-a899-d61239b9c89c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biases : [array([-0.59735223,  0.1791262 ,  0.13939366,  0.16128227,  0.2511386 ,\n",
            "        0.20171382, -0.07107455, -0.28762917,  0.63472049, -0.01380613,\n",
            "        0.38756203,  0.2936603 ,  0.14880614, -0.17191088, -0.66631897,\n",
            "        0.17202213, -0.11031322,  0.33565659, -0.01016813,  0.09684837]), array([0.17077163])]\n",
            "Weights : [array([[ 1.71839603, -0.77774845, -1.26971271, -0.29734902, -0.79386375,\n",
            "        -0.56694369,  0.24768818,  0.65396919, -1.95963181, -0.22553756,\n",
            "        -1.4230382 ,  0.17028146,  0.80712804,  1.32497095,  2.12735194,\n",
            "        -1.31094846,  0.67948905, -0.71516892, -0.97838531, -1.32726196],\n",
            "       [ 2.01388296, -0.50755807, -1.1525019 , -0.23812349, -0.54282012,\n",
            "        -0.31716273,  0.16103594,  1.06509859, -1.99065216, -0.3806479 ,\n",
            "        -1.36387819, -0.53960303,  0.89883776,  1.47382572,  1.81213645,\n",
            "        -1.14539214,  0.77679954, -0.31922225, -1.29470723, -1.19140321]]), array([[ 2.92075301],\n",
            "       [-0.88996795],\n",
            "       [-1.74614383],\n",
            "       [-0.41380397],\n",
            "       [-0.87966573],\n",
            "       [-0.56352082],\n",
            "       [ 0.27480297],\n",
            "       [ 1.32598757],\n",
            "       [-3.07973537],\n",
            "       [-0.420148  ],\n",
            "       [-1.98903399],\n",
            "       [-0.26595173],\n",
            "       [ 1.32056629],\n",
            "       [ 2.24810274],\n",
            "       [ 3.10102179],\n",
            "       [-1.7945338 ],\n",
            "       [ 0.98998753],\n",
            "       [-0.74391918],\n",
            "       [-1.75816348],\n",
            "       [-1.9123013 ]])]\n",
            "Input Size : 2\n",
            "Hidden Nodes : [20]\n",
            "Output Size : 1 \n"
          ]
        }
      ]
    }
  ]
}