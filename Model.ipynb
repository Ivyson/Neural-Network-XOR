{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpq-VL8HcwOU",
        "outputId": "e17527c8-e93a-48bd-a2d6-ed603ccf4d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.5173704051808867\n",
            "Epoch 1000, Loss: 0.5163634496037595\n",
            "Epoch 2000, Loss: 0.4964701990604208\n",
            "Epoch 3000, Loss: 0.15899391888726833\n",
            "Epoch 4000, Loss: 0.07448776594201867\n",
            "Epoch 5000, Loss: 0.052775596712468106\n",
            "Epoch 6000, Loss: 0.042445003433887386\n",
            "Epoch 7000, Loss: 0.03623482525464983\n",
            "Epoch 8000, Loss: 0.032016174219274544\n",
            "Epoch 9000, Loss: 0.028926726760439045\n",
            "Epoch 10000, Loss: 0.026546191022612922\n",
            "Epoch 11000, Loss: 0.02464335486096725\n",
            "Epoch 12000, Loss: 0.023079633340566764\n",
            "Epoch 13000, Loss: 0.02176646417096844\n",
            "Epoch 14000, Loss: 0.020644365064037523\n",
            "Epoch 15000, Loss: 0.01967176418067306\n",
            "Epoch 16000, Loss: 0.01881864636002563\n",
            "Epoch 17000, Loss: 0.018062744781943987\n",
            "Epoch 18000, Loss: 0.017387157276994074\n",
            "Epoch 19000, Loss: 0.016778798893899546\n",
            "Epoch 20000, Loss: 0.01622736553212895\n",
            "Epoch 21000, Loss: 0.015724620888600608\n",
            "Epoch 22000, Loss: 0.015263894168241303\n",
            "Epoch 23000, Loss: 0.014839718845543791\n",
            "Epoch 24000, Loss: 0.014447568039106132\n",
            "Epoch 25000, Loss: 0.014083657442522206\n",
            "Epoch 26000, Loss: 0.013744796376267802\n",
            "Epoch 27000, Loss: 0.013428273693099325\n",
            "Epoch 28000, Loss: 0.013131769311806563\n",
            "Epoch 29000, Loss: 0.012853284856871913\n",
            "Epoch 30000, Loss: 0.012591088721778205\n",
            "Epoch 31000, Loss: 0.012343672147530613\n",
            "Epoch 32000, Loss: 0.012109713803278032\n",
            "Epoch 33000, Loss: 0.0118880509940394\n",
            "Epoch 34000, Loss: 0.011677656081260559\n",
            "Epoch 35000, Loss: 0.011477617038581509\n",
            "Epoch 36000, Loss: 0.011287121313920307\n",
            "Epoch 37000, Loss: 0.011105442354668935\n",
            "Epoch 38000, Loss: 0.010931928292762707\n",
            "Epoch 39000, Loss: 0.010765992392844082\n",
            "Epoch 40000, Loss: 0.010607104948415907\n",
            "Epoch 41000, Loss: 0.010454786374017085\n",
            "Epoch 42000, Loss: 0.010308601290659126\n",
            "Epoch 43000, Loss: 0.010168153440350602\n",
            "Epoch 44000, Loss: 0.010033081296034238\n",
            "Epoch 45000, Loss: 0.00990305425748442\n",
            "Epoch 46000, Loss: 0.009777769343094714\n",
            "Epoch 47000, Loss: 0.009656948303070635\n",
            "Epoch 48000, Loss: 0.009540335092137435\n",
            "Epoch 49000, Loss: 0.009427693650118942\n",
            "Predictions for XOR function:\n",
            "Input: [1 1] -> Predicted Output: [0.]\n",
            "Input: [1 1] -> Predicted Output: [0.]\n",
            "Input: [0 0] -> Predicted Output: [0.]\n",
            "Input: [0 1] -> Predicted Output: [1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self, input_size, hidden_nodes, output_size, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        :param input_size: Number of input neurons\n",
        "        :param hidden_nodes: List specifying number of neurons in each hidden layer\n",
        "        :param output_size: Number of output neurons\n",
        "        :param learning_rate: Learning rate for weight updates\n",
        "\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.hidden_nodes = hidden_nodes  # List specifying neurons per hidden layer\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Define the architecture: input layer → hidden layers → output layer\n",
        "        layer_sizes = [input_size] + hidden_nodes + [output_size]\n",
        "\n",
        "        # Initialize weights and biases dynamically\n",
        "        self.weights = [np.random.rand(layer_sizes[i], layer_sizes[i+1]) - 0.5 for i in range(len(layer_sizes) - 1)]\n",
        "        self.biases = [np.random.rand(layer_sizes[i+1]) - 0.5 for i in range(len(layer_sizes) - 1)]\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedForward(self, inputs):\n",
        "        # Forward propagation through all layers.......\n",
        "        self.layers = [inputs]  # Store activations of all layers\n",
        "        for i in range(len(self.weights)):\n",
        "            inputs = self.sigmoid(np.dot(inputs, self.weights[i]) + self.biases[i])\n",
        "            self.layers.append(inputs)  # Save outputs of [i+1] layer for backpropagation\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    # Back Prop, to update the weights and Biases of the nueral network\n",
        "    def backpropagation(self, target_output):\n",
        "        errors = [target_output - self.layers[-1]]  # Output layer error\n",
        "        deltas = [errors[0] * self.sigmoid_derivative(self.layers[-1])]  # Output layer delta\n",
        "\n",
        "        # Get Dltas For each hidden layer in reverse order\n",
        "        for i in range(len(self.hidden_nodes), 0, -1):\n",
        "            errors.insert(0, np.dot(deltas[0], self.weights[i].T))  # Error of previous layer\n",
        "            deltas.insert(0, errors[0] * self.sigmoid_derivative(self.layers[i]))  # Delta, previous layer\n",
        "\n",
        "        # Update weights and biases\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] += np.dot(self.layers[i].reshape(-1, 1), deltas[i].reshape(1, -1)) * self.learning_rate\n",
        "            self.biases[i] += deltas[i] * self.learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for i in range(len(X)):\n",
        "                self.feedForward(X[i])\n",
        "                self.backpropagation(y[i])\n",
        "                total_loss += np.sum(np.abs(y[i] - self.layers[-1]))\n",
        "\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {total_loss / len(X)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.feedForward(x) for x in X]\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "#  Desired Output/ Target Output\n",
        "y = np.array([\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0]\n",
        "])\n",
        "\n",
        "# Create A Nueral Network with 2 inputs, and 2 Hidden Layers with nodes each,\n",
        "nn = NeuralNetwork(input_size=2, hidden_nodes=[20], output_size=1, learning_rate=0.2)\n",
        "nn.train(X, y, epochs=50000)\n",
        "\"\"\"\n",
        "The Model is too small and the learning rate is pretty quick\n",
        "So, The 50 Thousands epochs are not tha much of a deal,\n",
        "ever since the model has to solve a basic problem\n",
        "\n",
        "\"\"\"\n",
        "# Test Data\n",
        "Test = np.array([ # Feed the model randomised data to see the accuracy\n",
        "    [1, 1],\n",
        "    [1, 1],\n",
        "    [0, 0],\n",
        "    [0, 1]\n",
        "])\n",
        "# tEST PREDICTION\n",
        "predictions = np.round(nn.predict(Test))\n",
        "print(\"Predictions for XOR function:\")\n",
        "for i in range(len(Test)):\n",
        "    print(f\"Input: {Test[i]} -> Predicted Output: {predictions[i]}\")\n"
      ]
    }
  ]
}