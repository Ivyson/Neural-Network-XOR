{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivyson/Neural-Network-XOR/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpq-VL8HcwOU",
        "outputId": "5031d67b-2b98-4c0f-9dbf-ca8418319d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.52\n",
            "Epoch 1000, Loss: 0.51\n",
            "Epoch 2000, Loss: 0.33\n",
            "Epoch 3000, Loss: 0.10\n",
            "Epoch 4000, Loss: 0.06\n",
            "Epoch 5000, Loss: 0.05\n",
            "Epoch 6000, Loss: 0.04\n",
            "Epoch 7000, Loss: 0.03\n",
            "Epoch 8000, Loss: 0.03\n",
            "Epoch 9000, Loss: 0.03\n",
            "Predictions for XOR function:\n",
            "Input: [1 1] -> Predicted Output: [0.]\n",
            "Input: [1 1] -> Predicted Output: [0.]\n",
            "Input: [0 0] -> Predicted Output: [0.]\n",
            "Input: [0 1] -> Predicted Output: [1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self, input_size, hidden_nodes, output_size, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        :param input_size: Number of input neurons\n",
        "        :param hidden_nodes: List specifying number of neurons in each hidden layer\n",
        "        :param output_size: Number of output neurons\n",
        "        :param learning_rate: Learning rate for weight updates\n",
        "\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.hidden_nodes = hidden_nodes  # List specifying neurons per hidden layer\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Define the architecture: input layer → hidden layers → output layer\n",
        "        layer_sizes = [input_size] + hidden_nodes + [output_size]\n",
        "\n",
        "        # Initialize weights and biases dynamically\n",
        "        self.weights = [np.random.rand(layer_sizes[i], layer_sizes[i+1]) - 0.5 for i in range(len(layer_sizes) - 1)]\n",
        "        self.biases = [np.random.rand(layer_sizes[i+1]) - 0.5 for i in range(len(layer_sizes) - 1)]\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedForward(self, inputs):\n",
        "        # Forward propagation through all layers.......\n",
        "        self.layers = [inputs]  # Store activations of all layers\n",
        "        for i in range(len(self.weights)):\n",
        "            inputs = self.sigmoid(np.dot(inputs, self.weights[i]) + self.biases[i])\n",
        "            self.layers.append(inputs)  # Save outputs of [i+1] layer for backpropagation\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    # Back Prop, to update the weights and Biases of the nueral network\n",
        "    def backpropagation(self, target_output):\n",
        "        errors = [target_output - self.layers[-1]]  # Output layer error\n",
        "        deltas = [errors[0] * self.sigmoid_derivative(self.layers[-1])]  # Output layer delta\n",
        "\n",
        "        # Get Dltas For each hidden layer in reverse order\n",
        "        for i in range(len(self.hidden_nodes), 0, -1):\n",
        "            errors.insert(0, np.dot(deltas[0], self.weights[i].T))  # Error of previous layer\n",
        "            deltas.insert(0, errors[0] * self.sigmoid_derivative(self.layers[i]))  # Delta, previous layer\n",
        "\n",
        "        # Update weights and biases\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] += np.dot(self.layers[i].reshape(-1, 1), deltas[i].reshape(1, -1)) * self.learning_rate\n",
        "            self.biases[i] += deltas[i] * self.learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for i in range(len(X)):\n",
        "                self.feedForward(X[i])\n",
        "                self.backpropagation(y[i])\n",
        "                total_loss += np.sum(np.abs(y[i] - self.layers[-1]))\n",
        "\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {(total_loss / len(X)):.2f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.feedForward(x) for x in X]\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "#  Desired Output/ Target Output\n",
        "y = np.array([\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0]\n",
        "])\n",
        "\n",
        "# Create A Nueral Network with 2 inputs, and 2 Hidden Layers with nodes each,\n",
        "nn = NeuralNetwork(input_size=2, hidden_nodes=[20], output_size=1, learning_rate=0.2)\n",
        "nn.train(X, y, epochs=10000)\n",
        "\"\"\"\n",
        "The Model is too small and the learning rate is pretty quick\n",
        "So, The 50 Thousands epochs are not tha much of a deal,\n",
        "ever since the model has to solve a basic problem\n",
        "\n",
        "\"\"\"\n",
        "# Test Data\n",
        "Test = np.array([ # Feed the model randomised data to see the accuracy\n",
        "    [1, 1],\n",
        "    [1, 1],\n",
        "    [0, 0],\n",
        "    [0, 1]\n",
        "])\n",
        "# tEST PREDICTION\n",
        "predictions = np.round(nn.predict(Test))\n",
        "print(\"Predictions for XOR function:\")\n",
        "for i in range(len(Test)):\n",
        "    print(f\"Input: {Test[i]} -> Predicted Output: {predictions[i]}\")\n"
      ]
    }
  ]
}